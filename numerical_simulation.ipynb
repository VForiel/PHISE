{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "# üìú **Abstract**\n",
    "\n",
    "</div>\n",
    "\n",
    "Nulling interferometry $^1$ is a promising technique for direct detection of exoplanets. However, the performance of current devices is limited by the sensitivity to any phase aberrations. The work presented here attempts to overcome those limitations by using a four-telescopes nulling interferometer architecture, called Kernel-Nuller $^2$, which includes a recombiner that positions the four signals in phase quadrature. This architecture is based on an integrated optical component containing 14 electronically controlled phase shifters, used to correct optical path differences that would be induced by manufacturing defects. The first part of the study consists in the development of an algorithm providing the delays to be injected into the component to optimize the performance of that device. The next step of this study deals with the analysis of the intensity distributions produced at the output of the Kernel-Nuller $^{2,3}$ through a series of observations, and then apply statistical tests and data treatment techniques to detect the presence¬†of¬†exoplanets.\n",
    "\n",
    "> **References**\n",
    "> 1. Bracewell, R.N., MacPhie, R.H., 1979. Searching for nonsolar planets. Icarus 38, 136‚Äì147. https://doi.org/10.1016/0019-1035(79)90093-9\n",
    "> 2. Martinache, F., Ireland, M.J., 2018. Kernel-nulling for a robust direct interferometric detection of extrasolar planets. A&A 619, A87. https://doi.org/10.1051/0004-6361/201832847\n",
    "> 3. Cvetojevic, N. et al., 2022. 3-beam self-calibrated Kernel nulling photonic interferometer. arXiv e-prints. https://doi.org/10.48550/arXiv.2206.04977\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "# **üñ•Ô∏è Simulation requirements**\n",
    "\n",
    "</div>\n",
    "\n",
    "## üì• Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import os\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.origin'] = 'lower'\n",
    "import astropy.units as u\n",
    "import astropy.constants as const\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output, display\n",
    "import sympy as sp\n",
    "import fitter\n",
    "import numba as nb\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import rotate\n",
    "from LRFutils import color\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Parameters\n",
    "\n",
    "<div align=center>\n",
    "üëâ <i><U>Only edit the following block</u></i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelength\n",
    "L = 1.65 * u.um\n",
    "\n",
    "# Telescopes properties\n",
    "TELESCOPE_POSITIONS = np.array([\n",
    "    [0, 0],\n",
    "    [1, 1],\n",
    "    [2, 1.5],\n",
    "    [3, 0.7],\n",
    "]) * 42.2 * u.m\n",
    "LATITUDE = -24.6275 * u.deg\n",
    "DECLINATION = -64.71 * u.deg\n",
    "FOV = 10 * u.mas # Field of view\n",
    "\n",
    "# Target properties\n",
    "ALPHA = 70 * u.deg # Parallactic angle\n",
    "THETA = 7 * u.mas # Angular spearation\n",
    "CONTRAST = 1e-2\n",
    "\n",
    "STAR_MAGNITUDE = 0 * u.mag\n",
    "SPECTRAL_WIDTH = 0.3 * u.um\n",
    "OPTICAL_EFFICIENCY = 0.01\n",
    "\n",
    "# Observation conditions\n",
    "DH = 24 * u.hourangle # Observation duration\n",
    "DT = 1 * u.s # Exposure time\n",
    "\n",
    "# Cophasing errors\n",
    "INPUT_CE_RMS = 100 * u.nm # ~100 nm for ground based telescopes, 10 to 1 nm for space telescopes\n",
    "SHIFTS_CE_RMS = 100 * u.nm\n",
    "SHIFTS_CE_OFFSET = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) * u.nm\n",
    "\n",
    "# SHIFTS_CE_OFFSET = np.array([1.64214688, 1.64216085, 0.00554631, 1.64884721, 1.62784278, 0.03160111, 0.0182902, 0.02791266, 0.01329669, 0.01020052, 1.63187602, 1.64524911, 0.02049508, 0.0165746]) * L.unit\n",
    "# SHIFTS_CE_RMS = L*0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing parameters (conversion to commonly used units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process units\n",
    "\n",
    "TELESCOPE_POSITIONS = TELESCOPE_POSITIONS.to(u.m)\n",
    "ALPHA = ALPHA.to(u.rad)\n",
    "THETA = THETA.to(u.mas)\n",
    "LATITUDE = LATITUDE.to(u.deg)\n",
    "DECLINATION = DECLINATION.to(u.deg)\n",
    "INPUT_CE_RMS = INPUT_CE_RMS.to(L.unit)\n",
    "SHIFTS_CE_RMS = SHIFTS_CE_RMS.to(L.unit)\n",
    "SHIFTS_CE_OFFSET = SHIFTS_CE_OFFSET.to(L.unit)\n",
    "ALPHA_RANGE = np.linspace(0,2*np.pi,360)*u.rad\n",
    "EXTENT = (-FOV.value, FOV.value, -FOV.value, FOV.value)\n",
    "H_RANGE = np.linspace(-DH/2, DH/2, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Utils\n",
    "\n",
    "Numpy `random.normal()` is not jit-able (on flight compilation), so we need to define our own random.normal function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jit random functions\n",
    "\n",
    "@nb.jit()\n",
    "def random_normal(loc, scale, size=1):\n",
    "    return np.random.normal(loc, scale, size)\n",
    "\n",
    "@nb.jit()\n",
    "def random_poisson(lam):\n",
    "    return np.random.poisson(lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only consider relative phases, so we only consider phase shift in `[0,wavelenght[`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bound phase between [0,wavelenght[\n",
    "\n",
    "@nb.njit()\n",
    "def bound_phase_njit(phase:float, wavelenght:float=L.value):\n",
    "    \"\"\"Bring a phase to the interval [0, wavelenght[.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - phase: Phase to bound (in distance unit)\n",
    "    - wavelenght: Wavelenght of the light (same unit as phase) \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Phase in the interval [0, wavelenght]\n",
    "    \"\"\"\n",
    "    return np.mod(phase, wavelenght)\n",
    "\n",
    "def bound_phase(phase:u.Quantity, wavelenght:u.Quantity=L):\n",
    "    \"\"\"Bring a phase to the interval [0, wavelenght[.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - phase: Phase to bound\n",
    "    - wavelenght: Wavelenght of the light\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Phase in the interval [0, wavelenght]\n",
    "    \"\"\"\n",
    "    return bound_phase_njit(phase.value, wavelenght.to(phase.unit).value) * phase.unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîâ Photon noise\n",
    "\n",
    "Light flux is expressed in Jensky:\n",
    "$$\n",
    "1\\:\\text{Jensky} = 1\\:Jy = 10^{-26}\\:W/m^2/Hz = 10^{-26}\\:J/s/m^2/Hz\n",
    "$$\n",
    "The flux $F_\\lambda$ for a star at different wavelengths is given by tables $^1$. The following one is an example for AB class stars such as Vega:\n",
    "\n",
    "| Band | $\\lambda$ ($\\mu m$) | $F_\\lambda$ ($Jy$) |\n",
    "|------|---------------------|--------------------|\n",
    "| V    | 0.55                | 3540               |\n",
    "| J    | 1.21                | 1630               |\n",
    "| H    | 1.65                | 1050               |\n",
    "| K    | 2.17                | 655                |\n",
    "| L    | 3.55                | 276                |\n",
    "\n",
    "The number of acquired photons per second is given by:\n",
    "\n",
    "$$\n",
    "n_{ph} = F_\\lambda \\times A \\times \\Delta \\nu \\times \\eta \\times 10^{-\\frac{M}{2.5}} / E_\\nu\n",
    "$$\n",
    "\n",
    "where $A$ is the collecting area of the telescope, $\\Delta \\lambda$ is the bandwidth, $\\eta$ is the transmission efficiency of the system, $M$ is the magnitude of the star, and $E_\\nu$ is the energy of a photon at the frequency $\\nu$.\n",
    "\n",
    "We can also express the bandwidth and eneergy in terms of the wavelength:\n",
    "$$\n",
    "\\Delta \\nu = \\frac{c}{\\lambda^2} \\Delta \\lambda\n",
    "$$\n",
    "$$\n",
    "E_\\nu = \\frac{h \\times c}{\\lambda}\n",
    "$$\n",
    "\n",
    "where $c$ is the speed of light, $h$ is the Planck constant.\n",
    "\n",
    "> **References**\n",
    "> 1. Allen's Astrophysical Quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_photons():\n",
    "    h = const.h.to(u.J * u.s)\n",
    "    c = const.c.to(u.m/u.s)\n",
    "    l = L.to(u.m)\n",
    "    dl = (3072 * u.nm).to(u.m)\n",
    "\n",
    "    f = 1050*u.Jy\n",
    "    a = 4 * np.pi * (4*u.m)**2\n",
    "    dv = c/l**2 * dl\n",
    "    n = 0.01\n",
    "    m = 0\n",
    "    e = h*c/l\n",
    "\n",
    "    print(h, c, l, dl)\n",
    "    print(f, a, dv, n, m, e)\n",
    "\n",
    "    return (f * a * dv * n * 10**(-m/2.5) / e).to(1/u.s)\n",
    "\n",
    "p = nb_photons()\n",
    "print(f\"{p:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "# ü§î **Context**\n",
    "\n",
    "</div>\n",
    "\n",
    "## üéØ Goal\n",
    "\n",
    "We aim to detect make direct detection of exoplanets. There is two main challenges to achieve this goal:\n",
    "- The **contrast**: the exoplanet is much fainter than the star it orbits. The contrast is typically of the order of $10^{-6}$ to $10^{-10}$.\n",
    "- The **angular separation**: the exoplanet is very close to the star. The angular separation depend on the distance of the exoplanet to the star and the distance of the star to the observer and can easily goes below the arcsecond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîé Detection methods\n",
    "\n",
    "It exist several methods to detect exoplanets. The most common are:\n",
    "- **Radial velocity method**: the exoplanet induce a wobble in the star it orbits. This wobble can be detected by the Doppler effect (the light is alternatively redshifted and blueshifted).\n",
    "- **Transit method**: the exoplanet pass in front of the star and block a fraction of the light. This fraction can be detected by the decrease of the star luminosity.\n",
    "- **Microlensing**: the exoplanet act as a lens and magnify the light of a background star. This magnification can be detected by the increase of the star luminosity.\n",
    "- **Astrometry**: the exoplanet induce a wobble in the star it orbits. This wobble can be detected by the change of the star position.\n",
    "- **Coronography**: the exoplanet is directly imaged. This is the most challenging method because of the contrast and the angular separation.\n",
    "\n",
    "<div align=center>\n",
    "<img src=\"img/detection_methods.jpg\" width=500px>\n",
    "<p><i>Paul Anthony Wilson - Exoplanet detection techniques</i><p>\n",
    "</div>\n",
    "\n",
    "Until now, the coronography was the only method allowing direct detection. But it has two main limitations:\n",
    "- It require huge telescopes in order to have a good angular resolution.\n",
    "- The contrast we can achieve is limited by unperfect fabrication process of the optical components which lead to undesired diffraction effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ûñ Nulling\n",
    "\n",
    "This is where the Nulling technic $^1$ come into play. The idea is to use two several telescopes and take advantage of destructives interferances to cancel the star light and using the fact that the planet is not perfectly in the line of sight, which will lead to an unperfect destructive interference, or in best scenarios, on constructive ones! This is a very challenging technic because it is highly phase sensitive and require a very good control of the optical path.\n",
    "\n",
    "<div align=center>\n",
    "<img src=\"img/nulling_principle.jpg\" width=500px>\n",
    "</div>\n",
    "\n",
    "In a perfect 2-telescope nulling system, we can express the two acquired electric field (cf. section \"Signal nature\" below) in a vector:\n",
    "\n",
    "$$\n",
    "E = \\begin{pmatrix}\n",
    "E_1 \\\\\n",
    "E_2\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "And then express the nulling operation using the following matrix:\n",
    "\n",
    "$$\n",
    "N = \\begin{pmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & -1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Such as it gives us two outputs with a constructive and a destructive interference (we will focus on the latter):\n",
    "\n",
    "$$\n",
    "N \\cdot E = \\begin{pmatrix}\n",
    "E_1 + E_2 \\\\\n",
    "E_1 - E_2\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "> **References**\n",
    "> 1. Bracewell, R.N., MacPhie, R.H., 1979. Searching for nonsolar planets. Icarus 38, 136‚Äì147. https://doi.org/10.1016/0019-1035(79)90093-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x2 nuller\n",
    "\n",
    "@nb.njit()\n",
    "def nuller_2x2(beams:np.ndarray[complex]) -> np.ndarray[complex]:\n",
    "    \"\"\"\n",
    "    Simulate a 2 input beam nuller.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - beams: Array of 2 input beams complex amplitudes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Array of 2 output beams complex amplitudes\n",
    "        - 1st output is the bright channel\n",
    "        - 2nd output is the dark channel\n",
    "    \"\"\"\n",
    "\n",
    "    # Nuller matrix\n",
    "    N = 1/np.sqrt(2) * np.array([\n",
    "        [1,   1],\n",
    "        [1,  -1],\n",
    "    ], dtype=np.complex128)\n",
    "\n",
    "    # Operation\n",
    "    return N @ beams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì° Projected telescope position\n",
    "\n",
    "The interferometry process depend on the projected geometry of the telescope position in the plane perpendicular to the line of sight. For each observation, we will then need to compute these projected positions in order to have the correct baseline lenght (and thus the correct phase shifts).\n",
    "\n",
    "These projected location can be computed using the following formula $^{1,2}$ :\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "u \\\\\n",
    "v\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "- \\sin(l) \\sin(h) & \\cos(h)\\\\\n",
    "\\sin(l) \\cos(h) \\sin(\\delta) + \\cos(l) \\cos(\\delta) & \\sin(h) \\sin(\\delta)\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "B_\\text{north} \\\\\n",
    "B_\\text{east}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "with\n",
    "- $l$ the latitude of the observatory\n",
    "- $h$ the hour angle\n",
    "- $\\delta$ the declination of the star\n",
    "\n",
    "> *Rerefence*\n",
    "> 1. Chingaipe, P.M. et al., 2023. High-contrast detection of exoplanets with a kernel-nuller at the VLTI. A&A 676, A43. https://doi.org/10.1051/0004-6361/202346118\n",
    "> 2. S√©gransan, D., 2007. Observability and UV coverage. New Astronomy Reviews 51, 597‚Äì603. https://doi.org/10.1016/j.newar.2007.06.005\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve UT positions\n",
    "\n",
    "def get_ut_position():\n",
    "\n",
    "    # UT coordinates... obtained on Google map üòÖ <- TODO: update with precise positions\n",
    "    UTs_coordinates = np.array([\n",
    "        [-70.4048732988764, -24.627602893919807],\n",
    "        [-70.40465753243652, -24.627118902835786],\n",
    "        [-70.40439460074228, -24.62681028261176],\n",
    "        [-70.40384287956437, -24.627033500373024]\n",
    "    ]) # ‚ö†Ô∏è Expressed in [longitude, latitude] to easily convert to [x, y]\n",
    "    \n",
    "    # We are only interested in the relative positions of the UTs\n",
    "    # The first UT is the reference\n",
    "    UTs_coordinates -= UTs_coordinates[0]\n",
    "\n",
    "    # Altitude of the UTs\n",
    "    earth_radius = 6_378_137 * u.m\n",
    "    UTs_elevation = 2_635 * u.m\n",
    "\n",
    "    # Angle to distance conversion\n",
    "    return np.tan((UTs_coordinates * u.deg).to(u.rad)) * (earth_radius + UTs_elevation)\n",
    "\n",
    "TELESCOPE_POSITIONS = get_ut_position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project baseline\n",
    "\n",
    "@nb.njit()\n",
    "def project_baseline_njit(\n",
    "    telescope_positions: np.ndarray[float] = TELESCOPE_POSITIONS.value,\n",
    "    h: float = 0,\n",
    "    l: float = LATITUDE.to(u.rad).value,\n",
    "    d: float = DECLINATION.to(u.rad).value,\n",
    ") -> np.ndarray[float]:\n",
    "    \"\"\"\n",
    "    Rotate the telescope positions by an angle alpha.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - telescope_positions: Telescope positions.\n",
    "    - h: Hour angle (in radian)\n",
    "    - l: Latitude (in radian)\n",
    "    - d: Declination (in radian)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Rotated telescope positions (same shape and unit as telescope_positions)\n",
    "    \"\"\"\n",
    "\n",
    "    M = np.array([\n",
    "        [ -np.sin(l)*np.sin(h),                                np.cos(h)          ],\n",
    "        [ np.sin(l)*np.cos(h)*np.sin(d) + np.cos(l)*np.cos(d), np.sin(h)*np.sin(d)],\n",
    "    ])\n",
    "\n",
    "    projected_telescope_positions = np.empty_like(telescope_positions)\n",
    "    for i in range(telescope_positions.shape[0]):\n",
    "        projected_telescope_positions[i] = M @ np.array([telescope_positions[i][1], telescope_positions[i][0]])\n",
    "\n",
    "    return projected_telescope_positions\n",
    "\n",
    "def project_baseline(\n",
    "    telescope_positions: u.Quantity = TELESCOPE_POSITIONS,\n",
    "    h: u.Quantity = 0*u.hourangle,\n",
    "    l: u.Quantity = LATITUDE,\n",
    "    d: u.Quantity = DECLINATION,\n",
    ") -> u.Quantity:\n",
    "    \"\"\"\n",
    "    Rotate the telescope positions by an angle alpha.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - telescope_positions: Array of telescope positions.\n",
    "    - h: Hour angle\n",
    "    - l: Latitude\n",
    "    - d: Declination\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Array of rotated telescope positions (same shape and unit as telescope_positions)\n",
    "    \"\"\"\n",
    "\n",
    "    return project_baseline_njit(\n",
    "            telescope_positions.value,\n",
    "            h.to(u.rad),\n",
    "            l.to(u.rad),\n",
    "            d.to(u.rad),\n",
    "    ) * telescope_positions.unit\n",
    "\n",
    "PROJECTED_TELESCOPE_POSITIONS = project_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot telescope positions\n",
    "\n",
    "def plot_telescope_positions(\n",
    "        h_range=np.linspace(-4,4,15) * 2*np.pi / 24 * u.rad,\n",
    "        latitude=LATITUDE,\n",
    "        declination=DECLINATION,\n",
    "        return_image=False\n",
    "    ):\n",
    "\n",
    "    _, ax = plt.subplots()\n",
    "\n",
    "    for i, h in enumerate(h_range):\n",
    "        UT1, UT2, UT3, UT4 = project_baseline(TELESCOPE_POSITIONS, h, latitude, declination)\n",
    "\n",
    "        ax.scatter(UT1[0], UT1[1], label=\"UT1\" if i==len(h_range)-1 else None, color=\"C0\", s=1+14*i/len(h_range))\n",
    "        ax.scatter(UT2[0], UT2[1], label=\"UT2\" if i==len(h_range)-1 else None, color=\"C1\", s=1+14*i/len(h_range))\n",
    "        ax.scatter(UT3[0], UT3[1], label=\"UT3\" if i==len(h_range)-1 else None, color=\"C2\", s=1+14*i/len(h_range))\n",
    "        ax.scatter(UT4[0], UT4[1], label=\"UT4\" if i==len(h_range)-1 else None, color=\"C3\", s=1+14*i/len(h_range))\n",
    "\n",
    "    UT1, UT2, UT3, UT4 = project_baseline(TELESCOPE_POSITIONS, 0*u.hourangle, latitude, declination)\n",
    "    ax.scatter(UT2[0], UT2[1], color=\"black\", marker=\"+\")\n",
    "    ax.scatter(UT3[0], UT3[1], color=\"black\", marker=\"+\")\n",
    "    ax.scatter(UT4[0], UT4[1], color=\"black\", marker=\"+\")\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlabel(f\"x [{UT1.unit}]\")\n",
    "    ax.set_ylabel(f\"y [{UT1.unit}]\")\n",
    "    ax.set_title(f\"Projected telescope positions over the time\")\n",
    "    plt.legend()\n",
    "\n",
    "    if return_image:\n",
    "        buffer = BytesIO()\n",
    "        plt.savefig(buffer,format='png')\n",
    "        plt.close()\n",
    "        return buffer.getvalue()\n",
    "    plt.show()\n",
    "\n",
    "def iplot_telescope_positions():\n",
    "    \n",
    "    h_range = np.linspace(-4,4,15) * 2*np.pi / 24 * u.rad\n",
    "\n",
    "    latitude_slider = widgets.FloatSlider(\n",
    "        value=LATITUDE.to(u.deg).value,\n",
    "        min=-90,\n",
    "        max=90,\n",
    "        step=0.01,\n",
    "        description='Latitude:',\n",
    "    )\n",
    "\n",
    "    declination_slider = widgets.FloatSlider(\n",
    "        value=DECLINATION.to(u.deg).value,\n",
    "        min=-90,\n",
    "        max=90,\n",
    "        step=0.01,\n",
    "        description='Declination:',\n",
    "    )\n",
    "\n",
    "    reset = widgets.Button(description=\"Reset to defalut\")\n",
    "\n",
    "    plot = widgets.Image(width=500,height=500)\n",
    "\n",
    "    def update_plot(*args):\n",
    "        img = plot_telescope_positions(h_range=h_range, latitude=latitude_slider.value*u.deg, declination=declination_slider.value*u.deg, return_image=True)\n",
    "        plot.value = img.getvalue()\n",
    "\n",
    "    def reset_values(*args):\n",
    "        latitude_slider.value = LATITUDE.to(u.deg).value\n",
    "        declination_slider.value = DECLINATION.to(u.deg).value\n",
    "\n",
    "    reset.on_click(reset_values)\n",
    "    latitude_slider.observe(update_plot, 'value')\n",
    "    declination_slider.observe(update_plot, 'value')\n",
    "    display(widgets.VBox([latitude_slider, declination_slider, plot, reset]))\n",
    "    update_plot()\n",
    "    return\n",
    "\n",
    "plot_telescope_positions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÜ Signal nature\n",
    "\n",
    "The star and the planet are point sources. Seen from a classical telescope, it will result in an image made of the objects convolution with the point spread function (PSF) of the telescope.\n",
    "\n",
    "$$\n",
    "I = O \\otimes PSF\n",
    "$$\n",
    "\n",
    "Here we consider the most simple PSF : the Airy disk. The Airy disk is the diffraction pattern of a point source by a circular aperture. It is given by:\n",
    "\n",
    "$$\n",
    "PSF = \\left(\\frac{2J_1(x)}{x}\\right)^2\n",
    "$$\n",
    "\n",
    "where $J_1$ is the Bessel function of the first kind of order 1 and $x = \\frac{2\\pi r}{\\lambda f}$ is the normalized radius of the Airy disk.\n",
    "\n",
    "Then, we focus the image in a monomode optical fiber which will basically only keep the main lobe of the PSF and reshape it in a Gaussian form. In this process, we lose the spatial information so we have no longer images, but the light flux of each object in the fiber can be simply described by a complex number.\n",
    "\n",
    "Using this formalism, the light flux of the star and the planet can  be described by only 2 complex numbers for each telescope, giving the amplitude and phase of each object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input electric fields\n",
    "\n",
    "@nb.njit()\n",
    "def get_input_fields_njit(\n",
    "    norm:float = 1,\n",
    "    angular_separation: float = THETA.to(u.rad).value,\n",
    "    parallactic_angle: float = ALPHA.to(u.rad).value,\n",
    "    wavelenght: float = L.to(u.m).value,\n",
    "    projected_telescope_positions: np.ndarray[float] = PROJECTED_TELESCOPE_POSITIONS.to(u.m).value,\n",
    ") -> np.ndarray[complex]:\n",
    "    \"\"\"\n",
    "    Get the phase of the 4 inputs according to the object and telescope positions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - norm: Total intensity of the signal.\n",
    "    - angular_separation: Angular separation (in radian).\n",
    "    - parallactic_angle: Parallactic angle (in radian).\n",
    "    - wavelenght: Wavelength (in meter).S\n",
    "    - telescope_positions: Projected telescope positions (in meter).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Acquired signals (complex amplitudes).\n",
    "    \"\"\"\n",
    "\n",
    "    acquired_signals = np.empty(projected_telescope_positions.shape[0], dtype=np.complex128)\n",
    "\n",
    "    # Rotare the projected telescope positions by the parallactic angle\n",
    "    rotated_projected_telescope_positions = np.empty(projected_telescope_positions.shape[0])\n",
    "    for i, t in enumerate(projected_telescope_positions):\n",
    "        rotated_projected_telescope_positions[i] = t[0] * np.cos(-parallactic_angle) - t[1] * np.sin(-parallactic_angle)\n",
    "\n",
    "    # Acquire the signals according to the angular separation\n",
    "    for i, p in enumerate(rotated_projected_telescope_positions):\n",
    "        introduced_phase = 2 * np.pi * p * np.sin(angular_separation) / wavelenght\n",
    "        acquired_signals[i] = np.sqrt(norm) * np.exp(1j * introduced_phase)\n",
    "\n",
    "    return acquired_signals / np.sqrt(rotated_projected_telescope_positions.shape[0])\n",
    "\n",
    "def get_input_fields(\n",
    "    norm:float = 1,\n",
    "    angular_separation: u.Quantity = THETA,\n",
    "    alpha: u.Quantity = ALPHA,\n",
    "    wavelenght: u.Quantity = L,\n",
    "    projected_telescope_positions: u.Quantity = PROJECTED_TELESCOPE_POSITIONS,\n",
    ") -> np.ndarray[complex]:\n",
    "    \"\"\"\n",
    "    Get the phase of the 4 inputs according to the object and telescope positions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - norm: Total intensity of the signal.\n",
    "    - angular_separation: Angular separation.\n",
    "    - alpha: Parallactic angle.\n",
    "    - wavelenght: Wavelength.\n",
    "    - projected_telescope_positions: Projected telescope positions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Array of acquired signals (complex amplitudes).\n",
    "    \"\"\"\n",
    "\n",
    "    return get_input_fields_njit(\n",
    "        norm,\n",
    "        angular_separation.to(u.rad).value,\n",
    "        alpha.to(u.rad).value,\n",
    "        wavelenght.to(u.m).value,\n",
    "        projected_telescope_positions.to(u.m).value,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String representation of signals\n",
    "\n",
    "def signals_as_str(signals: np.ndarray[complex]) -> str:\n",
    "    \"\"\"\n",
    "    Convert signals to a string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - signals : Signals to convert.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - String representation of the signals.\n",
    "    \"\"\"\n",
    "\n",
    "    res = \"\"\n",
    "    for i, s in enumerate(signals):\n",
    "        res += f\" - Telescope {i}:   {np.abs(s):.2e} *exp(i* {np.angle(s)/np.pi:.2f} *pi)   ->   {np.abs(s)**2:.2e}\\n\"\n",
    "    return res[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîâ Photon noise\n",
    "\n",
    "The photon noise is the noise due to the quantization of the light in photons. It is a Poisson noise and can be described by the following formula:\n",
    "\n",
    "$$\n",
    "\\sigma = \\sqrt{N}\n",
    "$$\n",
    "\n",
    "where $N$ is the number of photons.\n",
    "\n",
    "The number of photons can be computed using the Light flux $F_\\lambda$ of the star and the planet, the collecting area $A$ of the telescope, the bandwidth $\\Delta \\lambda$, the transmission efficiency $\\eta$, the magnitude $M$ of the star, and the energy of a photon $E_\\nu$ at the frequency $\\nu$.\n",
    "\n",
    "Light flux is expressed in Jensky:\n",
    "$$\n",
    "1\\:\\text{Jensky} = 1\\:Jy = 10^{-26}\\:W/m^2/Hz = 10^{-26}\\:J/s/m^2/Hz\n",
    "$$\n",
    "The flux $F_\\lambda$ for a star at different wavelengths is given by tables. The following one is an example for AB class stars such as Vega:\n",
    "\n",
    "| Band | $\\lambda$ ($\\mu m$) | $F_\\lambda$ ($Jy$) |\n",
    "|------|---------------------|--------------------|\n",
    "| V    | 0.55                | 3540               |\n",
    "| J    | 1.21                | 1630               |\n",
    "| H    | 1.65                | 1050               |\n",
    "| K    | 2.17                | 655                |\n",
    "| L    | 3.55                | 276                |\n",
    "\n",
    "The number of acquired photons per second is given by:\n",
    "\n",
    "$$\n",
    "N = F_\\lambda \\times A \\times \\Delta \\nu \\times \\eta \\times 10^{-\\frac{M}{2.5}} / E_\\nu\n",
    "$$\n",
    "\n",
    "where $A$ is the collecting area of the telescope, $\\Delta \\lambda$ is the bandwidth, $\\eta$ is the transmission efficiency of the system, $M$ is the magnitude of the star, and $E_\\nu$ is the energy of a photon at the frequency $\\nu$.\n",
    "\n",
    "We can also express the bandwidth and eneergy in terms of the wavelength:\n",
    "$$\n",
    "\\Delta \\nu = \\frac{c}{\\lambda^2} \\Delta \\lambda\n",
    "$$\n",
    "$$\n",
    "E_\\nu = \\frac{h \\times c}{\\lambda}\n",
    "$$\n",
    "\n",
    "where $c$ is the speed of light, $h$ is the Planck constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_photons(\n",
    "        l:u.Quantity = L,\n",
    "        dl:u.Quantity = SPECTRAL_WIDTH,\n",
    "        f:u.Quantity = 1050*u.Jy,\n",
    "        a:u.Quantity = 4 * np.pi * (4*u.m)**2,\n",
    "        n:float = OPTICAL_EFFICIENCY,\n",
    "        m:float = STAR_MAGNITUDE.to(u.mag).value,\n",
    "):\n",
    "    h = const.h.to(u.J * u.s)\n",
    "    c = const.c.to(u.m/u.s)\n",
    "    dv = c/l**2 * dl\n",
    "    e = h*c/l\n",
    "\n",
    "    return (f * a * dv * n * 10**(-m/2.5) / e).to(1/u.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star photons/s: 5.79e+09 1 / s\n",
      "Planet photons/s: 5.79e+07 1 / s\n",
      "Star signals:\n",
      " - Telescope 0:   3.81e+04 *exp(i* 0.00 *pi)   ->   1.45e+09\n",
      " - Telescope 1:   3.81e+04 *exp(i* 0.00 *pi)   ->   1.45e+09\n",
      " - Telescope 2:   3.81e+04 *exp(i* 0.00 *pi)   ->   1.45e+09\n",
      " - Telescope 3:   3.81e+04 *exp(i* 0.00 *pi)   ->   1.45e+09\n",
      "Planet signals:\n",
      " - Telescope 0:   3.81e+03 *exp(i* 0.00 *pi)   ->   1.45e+07\n",
      " - Telescope 1:   3.81e+03 *exp(i* -0.07 *pi)   ->   1.45e+07\n",
      " - Telescope 2:   3.81e+03 *exp(i* -0.64 *pi)   ->   1.45e+07\n",
      " - Telescope 3:   3.81e+03 *exp(i* -0.51 *pi)   ->   1.45e+07\n"
     ]
    }
   ],
   "source": [
    "# Other constants defintion\n",
    "\n",
    "STAR_FLUX = nb_photons()\n",
    "PLANET_FLUX = STAR_FLUX * CONTRAST\n",
    "\n",
    "REF_INTENSITY = STAR_FLUX.to(1/u.s).value / DT.to(u.s).value\n",
    "\n",
    "STAR_SIGNALS = get_input_fields(norm=STAR_FLUX, angular_separation=0*u.mas)\n",
    "PLANET_SIGNALS = get_input_fields(norm=PLANET_FLUX, angular_separation=THETA)\n",
    "\n",
    "SHIFTS_TOTAL_OPD = bound_phase_njit(SHIFTS_CE_OFFSET.to(L.unit).value + random_normal(0, SHIFTS_CE_RMS.to(L.unit).value, size=14), L.value) * L.unit\n",
    "\n",
    "IDEAL_SHIFTS = bound_phase(-SHIFTS_TOTAL_OPD, L)\n",
    "\n",
    "print(f\"Star photons/s: {STAR_FLUX:.2e}\")\n",
    "print(f\"Planet photons/s: {PLANET_FLUX:.2e}\")\n",
    "\n",
    "print(f\"Star signals:\\n{signals_as_str(STAR_SIGNALS)}\")\n",
    "print(f\"Planet signals:\\n{signals_as_str(PLANET_SIGNALS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÆ MMI\n",
    "\n",
    "The nulling operation is made using Multi Mode Interferometer (MMI). It consist in a multimode waveguide taking several monomode fibers as input and output. The multimode waveguide is shaped in order to produce a specific interference operation, such as spreading the light of an input on all the output, or opposite, gathering the light of all the input on a single output.\n",
    "\n",
    "To design a simple nuller, we then need a 2x2 MMI that gather (ie. create a constructive interference) all the input light on a single output. The other output is then a \"nulled\" output, where there is actually all the inputs light but in phase opposition, resulting in a destructive interference.\n",
    "\n",
    "<div align=center>\n",
    "<img src=\"img/mmi.png\" width=400px>\n",
    "\n",
    "*Numerical simulation of a 3x3 gathering MMI, taken from the paper of Cvetojevic et. al., 2022 $^1$*\n",
    "\n",
    "</div>\n",
    "\n",
    "> **Reference**\n",
    "> 1. Cvetojevic, N. et al., 2022. 3-beam self-calibrated Kernel nulling photonic interferometer. arXiv e-prints. https://doi.org/10.48550/arXiv.2206.04977"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÄ Recombiner\n",
    "\n",
    "The recombiner is also an MMI that will place the signals in phase quadrature. A particularity is that the output of the recombiner contain a symmetry. We will take advantage of this in the Kernel step.\n",
    "\n",
    "<div align=center>\n",
    "<img src=\"img/recombiner.png\" width=500px>\n",
    "\n",
    "*Action of a 2x2 recombiner MMI, taking 2 different combination of 4 nulled signals as input. Taken from the paper of Romain Laugier et al., 2020 $^1$*\n",
    "\n",
    "</div>\n",
    "\n",
    "In a 2 input case, we can express the recombiner operation using the following matrix:\n",
    "\n",
    "$$  \n",
    "R = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}\n",
    "e^{i\\pi/4} & e^{-i\\pi/4} \\\\\n",
    "e^{-i\\pi/4} & e^{i\\pi/4}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "> **Reference**\n",
    "> 1. Laugier, R., Cvetojevic, N., Martinache, F., 2020. Kernel nullers for an arbitrary number of apertures. A&A 642, A202. https://doi.org/10.1051/0004-6361/202038866\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recombiner 2x2\n",
    "\n",
    "@nb.njit()\n",
    "def splitmix_2x2(beams:np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Simulate a 2 input beam split and mix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - beams: Array of 2 input beams complex amplitudes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Array of 2 output beams complex amplitudes\n",
    "    \"\"\"\n",
    "\n",
    "    theta:float=np.pi/2\n",
    "\n",
    "    # Splitter matrix\n",
    "    S = 1/np.sqrt(2) * np.array([\n",
    "        [np.exp(1j*theta/2), np.exp(-1j*theta/2)],\n",
    "        [np.exp(-1j*theta/2), np.exp(1j*theta/2)]\n",
    "    ])\n",
    "\n",
    "    # Operation\n",
    "    return S @ beams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí† Kernel\n",
    "\n",
    "The idea of the kernel is to acquire and substract the pairs of recombined output. As these pairs share symmetrical properties, this substraction will cancel the star light even with first order phase aberations while keeping the planet light!\n",
    "\n",
    "Moreover, it modify the nuller response (cf. \"Transmission maps\" section below) in an asymetric way which is interesting for us as it gives us more information to constrain the planet position.\n",
    "\n",
    "Demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formal demonstration\n",
    "\n",
    "def demonstration():\n",
    "\n",
    "    # Elements definition\n",
    "    I = sp.IndexedBase(\"I\", real=True)  # Kernel intensity\n",
    "    E = sp.IndexedBase(\"E\")  # Electric field\n",
    "    A = sp.IndexedBase(\"A\", real=True)  # Amplitude\n",
    "    P = sp.IndexedBase(\"phi\", real=True)  # Relative phase\n",
    "    T = sp.IndexedBase(\"theta\", real=True)  # Phase perturbation\n",
    "    a = sp.symbols(\"a\", cls=sp.Idx)  # First dark\n",
    "    b = sp.symbols(\"b\", cls=sp.Idx)  # Second dark\n",
    "    s = sp.symbols(\"s\", cls=sp.Idx)  # Star index\n",
    "    p = sp.symbols(\"p\", cls=sp.Idx)  # Planet index\n",
    "\n",
    "    # Intensity in a dark output is the sum of the intensities coming from the star and from the planet\n",
    "    Ia = I[a, s] + I[a, p]\n",
    "    Ib = I[b, s] + I[b, p]\n",
    "    print(\"Input intensities:\")\n",
    "    display(Ia, Ib)\n",
    "\n",
    "    # Developping Intensities as interference of the electrical fields\n",
    "    Ias = abs(E[1, s] + E[2, s] + E[3, s] + E[4, s]) ** 2\n",
    "    Iap = abs(E[1, p] + E[2, p] + E[3, p] + E[4, p]) ** 2\n",
    "    Ibs = abs(E[1, s] + E[2, s] + E[3, s] + E[4, s]) ** 2\n",
    "    Ibp = abs(E[1, p] + E[2, p] + E[3, p] + E[4, p]) ** 2\n",
    "\n",
    "    Ia = Ia.subs(I[a, s], Ias).subs(I[a, p], Iap)\n",
    "    Ib = Ia.subs(I[b, s], Ibs).subs(I[b, p], Ibp)\n",
    "    print(\"Fields contributions:\")\n",
    "    display(Ia, Ib)\n",
    "\n",
    "    # Expressing the electric fields as a function of the amplitudes and the relative phases\n",
    "    E1s = A[s]\n",
    "    E2s = A[s] * (1 + sp.I * T[2])\n",
    "    E3s = A[s] * (1 + sp.I * T[3])\n",
    "    E4s = A[s] * (1 + sp.I * T[4])\n",
    "    E1p = A[p] * sp.exp(sp.I * P[1])\n",
    "    E2p = A[p] * sp.exp(sp.I * P[2]) * (1 + sp.I * T[2])\n",
    "    E3p = A[p] * sp.exp(sp.I * P[3]) * (1 + sp.I * T[3])\n",
    "    E4p = A[p] * sp.exp(sp.I * P[4]) * (1 + sp.I * T[4])\n",
    "\n",
    "    # Relative phase : E1 -> 0, E2 -> pi, E3 -> pi/2, E4 -> -pi/2\n",
    "    Ia = (\n",
    "        Ia.subs(E[1, s], E1s)\n",
    "        .subs(E[2, s], -E2s)\n",
    "        .subs(E[3, s], sp.I * E3s)\n",
    "        .subs(E[4, s], -sp.I * E4s)\n",
    "    )\n",
    "    Ia = (\n",
    "        Ia.subs(E[1, p], E1p)\n",
    "        .subs(E[2, p], -E2p)\n",
    "        .subs(E[3, p], sp.I * E3p)\n",
    "        .subs(E[4, p], -sp.I * E4p)\n",
    "    )\n",
    "    # Relative phase : E1 -> 0, E2 -> pi, E3 -> -pi/2, E4 -> pi/2\n",
    "    Ib = (\n",
    "        Ib.subs(E[1, p], E1p)\n",
    "        .subs(E[2, p], -E2p)\n",
    "        .subs(E[3, p], -sp.I * E3p)\n",
    "        .subs(E[4, p], sp.I * E4p)\n",
    "    )\n",
    "    Ib = (\n",
    "        Ib.subs(E[1, s], E1s)\n",
    "        .subs(E[2, s], -E2s)\n",
    "        .subs(E[3, s], -sp.I * E3s)\n",
    "        .subs(E[4, s], sp.I * E4s)\n",
    "    )\n",
    "    print(\"Decomposition in amplitudes and phases:\")\n",
    "    display(Ia.expand().simplify(), Ib.expand().simplify())\n",
    "\n",
    "    # Kernel intensity\n",
    "    Ik = Ia - Ib\n",
    "    print(\"Difference between the signals\")\n",
    "    display(Ik.expand().simplify())\n",
    "\n",
    "# demonstration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üå°Ô∏è Thermo-optic phase shifter\n",
    "\n",
    "In practice, we are often limited by the fabrication process of the optical components. The imperfections can lead into phase aberations that will degrade the Kernel-Nuller performance. An attempt to correct these aberations consist in using thermo-optic phase shifters. It consist in a waveguide with a heater that will modify the refractive index of the waveguide and thus the phase of the light passing through it.\n",
    "\n",
    "As the size of the waveguide is very small, the thermal inertia is very low and the phase can be modified very quickly, in a milisecond time scale. This is a very interesting solution to correct phase aberations, even in real time if we encounter variable phase aberation sources.\n",
    "\n",
    "<div align=center>\n",
    "<img src=\"img/thermo-optic_phase_shifter.png\" width=500px>\n",
    "</div>\n",
    "\n",
    "In this simulation, one will simply modelize these phase shifter as a phase shift in the signal.\n",
    "\n",
    "$$\n",
    "P = e^{i\\phi} = e^{i\\frac{2\\pi}{\\lambda} \\Delta L}\n",
    "$$\n",
    "\n",
    "Where $\\phi$ and $\\Delta L$ are proportional to the power injected in the heater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase shift\n",
    "\n",
    "@nb.njit()\n",
    "def phase_shift_njit(\n",
    "    beam: complex | np.ndarray[complex],\n",
    "    phase: float | np.ndarray[float],\n",
    "    wavelenght: float = L.value,\n",
    ") -> complex | np.ndarray[complex]:\n",
    "    \"\"\"\n",
    "    De-phase the input beam by heating the fiber with an electrical current.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - beam: input beam complex amplitude\n",
    "    - phase: phase to add (in same unit as wavelenght)\n",
    "    - wavelenght: wavelength\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Output beam complex amplitude\n",
    "    \"\"\"\n",
    "    return beam * np.exp(1j * 2 * np.pi * phase / wavelenght)\n",
    "\n",
    "\n",
    "def phase_shift(\n",
    "    beam: complex | np.ndarray[complex], phase: u.Quantity, wavelenght: u.Quantity = L\n",
    ") -> complex | np.ndarray[complex]:\n",
    "    \"\"\"\n",
    "    De-phase the input beam by heating the fiber with an electrical current.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - beam: input beam complex amplitude\n",
    "    - phase: phase to add\n",
    "    - wavelenght: wavelength\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Output beam complex amplitude\n",
    "    \"\"\"\n",
    "    return phase_shift_njit(beam, phase.to(wavelenght.unit).value, wavelenght.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "# üí° **Our approach**\n",
    "\n",
    "</div>\n",
    "\n",
    "## üèóÔ∏è Current architecture\n",
    "\n",
    "To implement the 4 telescope tunable Kernel-Nuller, we splitted the 4x4 MMI into series of 2x2 MMI separated by phase shifters.\n",
    "\n",
    "<div align=center>\n",
    "<img src=\"img/scheme.png\" width=1000px>\n",
    "\n",
    "*Architecture of our Kernel-Nuller. N suqares are the 2x2 nullers, S squares are the 2x2 recombiners and P rectangles are the phase shifters*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel nuller\n",
    "\n",
    "@nb.njit()\n",
    "def kn_fields_njit(\n",
    "    beams: np.ndarray[complex],\n",
    "    shifts: np.ndarray[float] = np.zeros(14),\n",
    "    shifts_total_opd: np.ndarray[float] = SHIFTS_TOTAL_OPD.to(L.unit).value,\n",
    "    wavelenght: float = L.value,\n",
    ") -> tuple[np.ndarray[float], np.ndarray[float], np.ndarray[float], float]:\n",
    "    \"\"\"\n",
    "    Simulate a 4 telescope Kernel-Nuller propagation using a numeric approach\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - beams: Array of 4 input beams complex amplitudes\n",
    "    - shifts: Array of 14 injected OPD (in wavelenght unit)\n",
    "    - shifts_total_opd: Array of 14 intrasic OPD (in wavelenght unit)\n",
    "    - wavelenght: Wavelength of the light\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Array of 3 null outputs electric fields\n",
    "    - Array of 6 dark outputs electric fields\n",
    "    - Bright output electric fields\n",
    "    \"\"\"\n",
    "\n",
    "    shifts = bound_phase_njit(shifts + shifts_total_opd, wavelenght)\n",
    "\n",
    "    # First layer of pahse shifters\n",
    "    nuller_inputs = phase_shift_njit(beams, shifts[:4], wavelenght)\n",
    "\n",
    "    # First layer of nulling\n",
    "    N1 = nuller_2x2(nuller_inputs[:2])\n",
    "    N2 = nuller_2x2(nuller_inputs[2:])\n",
    "\n",
    "    # Second layer of phase shifters\n",
    "    N1_shifted = phase_shift_njit(N1, shifts[4:6], wavelenght)\n",
    "    N2_shifted = phase_shift_njit(N2, shifts[6:8], wavelenght)\n",
    "\n",
    "    # Second layer of nulling\n",
    "    N3 = nuller_2x2(np.array([N1_shifted[0], N2_shifted[0]]))\n",
    "    N4 = nuller_2x2(np.array([N1_shifted[1], N2_shifted[1]]))\n",
    "\n",
    "    nulls = np.array([N3[1], N4[0], N4[1]], dtype=np.complex128)\n",
    "    bright = N3[0]\n",
    "\n",
    "    # Beam splitting\n",
    "    S_inputs = np.array([N3[1], N3[1], N4[0], N4[0], N4[1], N4[1]]) * 1 / np.sqrt(2)\n",
    "\n",
    "    # Last layer of phase shifters\n",
    "    S_inputs = phase_shift_njit(S_inputs, shifts[8:], wavelenght)\n",
    "\n",
    "    # Beam mixing\n",
    "    S1_output = splitmix_2x2(np.array([S_inputs[0], S_inputs[2]]))\n",
    "    S2_output = splitmix_2x2(np.array([S_inputs[1], S_inputs[4]]))\n",
    "    S3_output = splitmix_2x2(np.array([S_inputs[3], S_inputs[5]]))\n",
    "\n",
    "    darks = np.array(\n",
    "        [\n",
    "            S1_output[0],\n",
    "            S1_output[1],\n",
    "            S2_output[0],\n",
    "            S2_output[1],\n",
    "            S3_output[0],\n",
    "            S3_output[1],\n",
    "        ],\n",
    "        dtype=np.complex128,\n",
    "    )\n",
    "\n",
    "    return nulls, darks, bright\n",
    "\n",
    "def kn_fields(\n",
    "    beams: np.ndarray[complex],\n",
    "    shifts: u.Quantity = np.zeros(14) * L.unit,\n",
    "    shifts_total_opd: u.Quantity = SHIFTS_TOTAL_OPD,\n",
    "    wavelenght: u.Quantity = L,\n",
    ") -> tuple[np.ndarray[float], np.ndarray[float], np.ndarray[float], float]:\n",
    "    \"\"\"\n",
    "    Simulate a 4 telescope Kernel-Nuller propagation using a numeric approach\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - beams: Array of 4 input beams complex amplitudes\n",
    "    - shifts: Array of 14 injected OPD\n",
    "    - shifts_total_opd: Array of 14 intrasic OPD\n",
    "    - wavelenght: Wavelength of the light\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Array of 3 null outputs electric fields\n",
    "    - Array of 6 dark outputs electric fields\n",
    "    - Bright output electric fields\n",
    "    \"\"\"\n",
    "\n",
    "    return kn_fields_njit(\n",
    "        beams,\n",
    "        shifts.to(wavelenght.unit).value,\n",
    "        shifts_total_opd.to(wavelenght.unit).value,\n",
    "        wavelenght.value,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kn_phase_effect(\n",
    "        shifts=np.zeros(14)*L.unit,\n",
    "        inputs=np.array([1+0j, 1+0j, 1+0j, 1+0j]),\n",
    "        plot=True\n",
    "    ):\n",
    "\n",
    "    input1_signal = np.array([inputs[0], 0, 0, 0])\n",
    "    input2_signal = np.array([0, inputs[1], 0, 0])\n",
    "    input3_signal = np.array([0, 0, inputs[2], 0])\n",
    "    input4_signal = np.array([0, 0, 0, inputs[3]])\n",
    "\n",
    "    nulls1, darks1, bright1 = kn_fields(input1_signal, shifts)\n",
    "    nulls2, darks2, bright2 = kn_fields(input2_signal, shifts)\n",
    "    nulls3, darks3, bright3 = kn_fields(input3_signal, shifts)\n",
    "    nulls4, darks4, bright4 = kn_fields(input4_signal, shifts)\n",
    "\n",
    "    # Using first signal as reference\n",
    "    nulls2 = np.abs(nulls2) * np.exp(1j * (np.angle(nulls2) - np.angle(nulls1)))\n",
    "    nulls3 = np.abs(nulls3) * np.exp(1j * (np.angle(nulls3) - np.angle(nulls1)))\n",
    "    nulls4 = np.abs(nulls4) * np.exp(1j * (np.angle(nulls4) - np.angle(nulls1)))\n",
    "    darks2 = np.abs(darks2) * np.exp(1j * (np.angle(darks2) - np.angle(darks1)))\n",
    "    darks3 = np.abs(darks3) * np.exp(1j * (np.angle(darks3) - np.angle(darks1)))\n",
    "    darks4 = np.abs(darks4) * np.exp(1j * (np.angle(darks4) - np.angle(darks1)))\n",
    "    bright2 = np.abs(bright2) * np.exp(1j * (np.angle(bright2) - np.angle(bright1)))\n",
    "    bright3 = np.abs(bright3) * np.exp(1j * (np.angle(bright3) - np.angle(bright1)))\n",
    "    bright4 = np.abs(bright4) * np.exp(1j * (np.angle(bright4) - np.angle(bright1)))\n",
    "    nulls1 = np.abs(nulls1) * np.exp(1j * 0)\n",
    "    darks1 = np.abs(darks1) * np.exp(1j * 0)\n",
    "    bright1 = np.abs(bright1) * np.exp(1j * 0)\n",
    "\n",
    "    _, axs = plt.subplots(2, 6, figsize=(20, 7.5), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "    # Bright output\n",
    "    axs[0,0].scatter(np.angle(bright1), np.abs(bright1), color=\"yellow\", label='Input 1', alpha=0.5)\n",
    "    axs[0,0].plot([0, np.angle(bright1)], [0, np.abs(bright1)], color=\"yellow\", alpha=0.5)\n",
    "    axs[0,0].scatter(np.angle(bright2), np.abs(bright2), color=\"green\", label='Input 2', alpha=0.5)\n",
    "    axs[0,0].plot([0, np.angle(bright2)], [0, np.abs(bright2)], color=\"green\", alpha=0.5)\n",
    "    axs[0,0].scatter(np.angle(bright3), np.abs(bright3), color=\"red\", label='Input 3', alpha=0.5)\n",
    "    axs[0,0].plot([0, np.angle(bright3)], [0, np.abs(bright3)], color=\"red\", alpha=0.5)\n",
    "    axs[0,0].scatter(np.angle(bright4), np.abs(bright4), color=\"blue\", label='Input 4', alpha=0.5)\n",
    "    axs[0,0].plot([0, np.angle(bright4)], [0, np.abs(bright4)], color=\"blue\", alpha=0.5)\n",
    "    axs[0,0].set_title('Bright output')\n",
    "\n",
    "    for null in range(3):\n",
    "        axs[0,null+1].scatter(np.angle(nulls1[null]), np.abs(nulls1[null]), color=\"yellow\", label='Input 1', alpha=0.5)\n",
    "        axs[0,null+1].plot([0, np.angle(nulls1[null])], [0, np.abs(nulls1[null])], color=\"yellow\", alpha=0.5)\n",
    "        axs[0,null+1].scatter(np.angle(nulls2[null]), np.abs(nulls2[null]), color=\"green\", label='Input 2', alpha=0.5)\n",
    "        axs[0,null+1].plot([0, np.angle(nulls2[null])], [0, np.abs(nulls2[null])], color=\"green\", alpha=0.5)\n",
    "        axs[0,null+1].scatter(np.angle(nulls3[null]), np.abs(nulls3[null]), color=\"red\", label='Input 3', alpha=0.5)\n",
    "        axs[0,null+1].plot([0, np.angle(nulls3[null])], [0, np.abs(nulls3[null])], color=\"red\", alpha=0.5)\n",
    "        axs[0,null+1].scatter(np.angle(nulls4[null]), np.abs(nulls4[null]), color=\"blue\", label='Input 4', alpha=0.5)\n",
    "        axs[0,null+1].plot([0, np.angle(nulls4[null])], [0, np.abs(nulls4[null])], color=\"blue\", alpha=0.5)\n",
    "        axs[0,null+1].set_title(f'Null output {null+1}')\n",
    "\n",
    "    for dark in range(6):\n",
    "        axs[1,dark].scatter(np.angle(darks1[dark]), np.abs(darks1[dark]), color=\"yellow\", label='I1', alpha=0.5)\n",
    "        axs[1,dark].plot([0, np.angle(darks1[dark])], [0, np.abs(darks1[dark])], color=\"yellow\", alpha=0.5)\n",
    "        axs[1,dark].scatter(np.angle(darks2[dark]), np.abs(darks2[dark]), color=\"green\", label='I2', alpha=0.5)\n",
    "        axs[1,dark].plot([0, np.angle(darks2[dark])], [0, np.abs(darks2[dark])], color=\"green\", alpha=0.5)\n",
    "        axs[1,dark].scatter(np.angle(darks3[dark]), np.abs(darks3[dark]), color=\"red\", label='I3', alpha=0.5)\n",
    "        axs[1,dark].plot([0, np.angle(darks3[dark])], [0, np.abs(darks3[dark])], color=\"red\", alpha=0.5)\n",
    "        axs[1,dark].scatter(np.angle(darks4[dark]), np.abs(darks4[dark]), color=\"blue\", label='I4', alpha=0.5)\n",
    "        axs[1,dark].plot([0, np.angle(darks4[dark])], [0, np.abs(darks4[dark])], color=\"blue\", alpha=0.5)\n",
    "        axs[1,dark].set_title(f'Dark output {dark+1}')\n",
    "\n",
    "    axs[0, 4].axis(\"off\")\n",
    "    axs[0, 5].axis(\"off\")\n",
    "\n",
    "    axs[0,0].legend()\n",
    "\n",
    "    if not plot:\n",
    "        plot = BytesIO()\n",
    "        plt.savefig(plot, format='png')\n",
    "        plt.close()\n",
    "        return plot.getvalue()\n",
    "    plt.show()\n",
    "\n",
    "plot_kn_phase_effect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è Transmission maps\n",
    "\n",
    "The nulling technic with two telescope show a limitation: if the planet light arrive on the two telescopes with a phase shift of $2n\\pi$, the light will also be cancelled. It result in a comb-shaped transmission map $^1$, perpendicular to the baseline (there is clear bands where it's optimal to detect the planet and black bands where we will mostly destroy the planet light).\n",
    "\n",
    "The idea of Bracewell was to rotate the baseline in order to let the planet pass through the clear bands at some point. After an entire rotation of the baseline, we will have a sinusoidal signal from which the frequency will indicate us the distance of the planet to it's star, and the phase will give us a clue about the angle between the axes star-planet and the axes of the baseline. Thus, as the transmission map is symmetric, we can constrain the planet position to 2 possible locations, on both sides of the star.\n",
    "\n",
    "Here, we are using 4 telescopes, resulting in more complexe transmission maps than simple combs, but the principle is the same.\n",
    "\n",
    "> **Reference**\n",
    "> 1. Bracewell, R.N., MacPhie, R.H., 1979. Searching for nonsolar planets. Icarus 38, 136‚Äì147. https://doi.org/10.1016/0019-1035(79)90093-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit()\n",
    "def get_uv_map_njit(resolution:int=100, fov:float=FOV.to(u.rad).value) -> tuple[np.ndarray[float], np.ndarray[float], np.ndarray[float], np.ndarray[float]]:\n",
    "    \"\"\"\n",
    "    Generate a map of theta and alpha values for a given resolution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - resolution: Resolution of the map\n",
    "    - fov: Range of field of view values\n",
    "    - alpha: Initial parallactic angle\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Normalized U map (resolution x resolution)\n",
    "    - Normalized V map (resolution x resolution)\n",
    "    - Theta map (resolution x resolution)\n",
    "    - Alpha map (resolution x resolution)\n",
    "    \"\"\"\n",
    "\n",
    "    # Recreate np.meshgrid() compatible with numba\n",
    "    x = np.zeros((resolution, resolution))\n",
    "    y = np.zeros((resolution, resolution))\n",
    "    for i, v in enumerate(np.linspace(-1, 1, resolution)):\n",
    "        x[:, i] = v\n",
    "        y[i, :] = v\n",
    "\n",
    "    theta_map = np.sqrt(x**2 + y**2) * fov\n",
    "    alpha_map = np.arctan2(y, x)\n",
    "    alpha_map = alpha_map % (2*np.pi)\n",
    "\n",
    "    return x, y, theta_map, alpha_map\n",
    "\n",
    "def get_uv_map(\n",
    "    resolution: int = 100,\n",
    "    fov: u.Quantity = FOV,\n",
    "    alpha:u.Quantity = ALPHA,\n",
    ") -> tuple[np.ndarray[float], np.ndarray[float], u.Quantity, u.Quantity]:\n",
    "    \"\"\"\n",
    "    Generate a map of theta and alpha values for a given resolution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - resolution: Resolution of the map\n",
    "    - fov: Range of field of view values\n",
    "    - alpha: Initial parallactic angle\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Normalized U map (resolution x resolution)\n",
    "    - Normalized V map (resolution x resolution)\n",
    "    - Theta map (resolution x resolution)\n",
    "    - Alpha map (resolution x resolution)\n",
    "    \"\"\"\n",
    "\n",
    "    x, y, theta_map, alpha_map = get_uv_map_njit(resolution=resolution, fov=fov.to(u.rad).value)\n",
    "\n",
    "    theta_map = (theta_map * u.rad).to(fov.unit)\n",
    "    alpha_map = (alpha_map * u.rad).to(alpha.unit)\n",
    "\n",
    "    return x, y, theta_map, alpha_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uv_map():\n",
    "    x, y, theta_map, alpha_map = get_uv_map()\n",
    "\n",
    "    _, axs = plt.subplots(2, 2, figsize=(13, 10))\n",
    "    \n",
    "    im = axs[0, 0].imshow(x, extent=EXTENT, cmap='viridis')\n",
    "    axs[0, 0].set_title(\"U map (px)\")\n",
    "    axs[0, 0].set_xlabel(\"U\")\n",
    "    axs[0, 0].set_ylabel(\"V\")\n",
    "    plt.colorbar(im, ax=axs[0, 0])\n",
    "\n",
    "    im = axs[0, 1].imshow(y, extent=EXTENT, cmap='viridis')\n",
    "    axs[0, 1].set_title(\"V map (px)\")\n",
    "    axs[0, 1].set_xlabel(\"U\")\n",
    "    axs[0, 1].set_ylabel(\"V\")\n",
    "    plt.colorbar(im, ax=axs[0, 1])\n",
    "\n",
    "    im = axs[1, 0].imshow(theta_map.value, extent=EXTENT, cmap='viridis')\n",
    "    axs[1, 0].set_title(f\"Theta map ({theta_map.unit})\")\n",
    "    axs[1, 0].set_xlabel(\"U\")\n",
    "    axs[1, 0].set_ylabel(\"V\")\n",
    "    plt.colorbar(im, ax=axs[1, 0])\n",
    "\n",
    "    im = axs[1, 1].imshow(alpha_map.value, extent=EXTENT, cmap='viridis')\n",
    "    axs[1, 1].set_title(f\"Alpha map ({alpha_map.unit})\")\n",
    "    axs[1, 1].set_xlabel(\"U\")\n",
    "    axs[1, 1].set_ylabel(\"V\")\n",
    "    plt.colorbar(im, ax=axs[1, 1])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# plot_uv_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit()\n",
    "def alpha_theta_to_fov_map_coord_njit(\n",
    "        alpha: float = ALPHA.to(u.rad).value,\n",
    "        theta: float = THETA.to(u.rad).value,\n",
    "        norm_by_fov: float = 1,\n",
    "    ) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Convert alpha and theta values to the x and y angle from the center of the field of view.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - alpha: Parallactic angle (rad)\n",
    "    - theta: Angular separation (rad)\n",
    "    - norm_by_fov: Field of view (rad)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - U value\n",
    "    - V value\n",
    "    \"\"\"\n",
    "\n",
    "    normalized_theta = theta / norm_by_fov\n",
    "\n",
    "    x = normalized_theta * np.cos(alpha)\n",
    "    y = normalized_theta * np.sin(alpha)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def alpha_theta_to_fov_map_coord(\n",
    "    alpha: u.Quantity = ALPHA,\n",
    "    theta: u.Quantity = THETA,\n",
    "    norm_by_fov: u.Quantity = 1*THETA.unit,\n",
    ") -> tuple[u.Quantity, u.Quantity]:\n",
    "    \"\"\"\n",
    "    Convert alpha and theta values to the x and y angle from the center of the field of view.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - alpha: Parallactic angle\n",
    "    - theta: Angular separation\n",
    "    - norm_by_fov: Field of view\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - U value\n",
    "    - V value\n",
    "    \"\"\"\n",
    "        \n",
    "    return alpha_theta_to_fov_map_coord_njit(\n",
    "        alpha = alpha.to(u.rad).value,\n",
    "        theta = theta.to(u.rad).value,\n",
    "        norm_by_fov = norm_by_fov.to(u.rad).value\n",
    "    ) * theta.unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit()\n",
    "def get_transmission_map_njit(\n",
    "    resolution: int = 100,\n",
    "    shifts: np.ndarray[float] = np.zeros(14),\n",
    "    shifts_total_opd: np.ndarray[float] = np.zeros(14),\n",
    "    projected_telescope_positions: np.ndarray[float] = PROJECTED_TELESCOPE_POSITIONS.value\n",
    ") -> tuple[np.ndarray[complex], np.ndarray[complex], np.ndarray[float]]:\n",
    "    \"\"\"\n",
    "    Generate all the kernel-nuller transmission maps for a given resolution\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - resolution: Resolution of the map\n",
    "    - shifts: Array of 14 injected OPD (in wavelenght unit)\n",
    "    - shifts_total_opd: Array of 14 intrasic OPD (in wavelenght unit)\n",
    "    - projected_telescope_positions: Telescope positions (in meter)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Null outputs map (3 x resolution x resolution)\n",
    "    - Dark outputs map (6 x resolution x resolution)\n",
    "    - Kernel outputs map (3 x resolution x resolution)\n",
    "    \"\"\"\n",
    "\n",
    "    _, _, theta_map, alpha_map = get_uv_map_njit(resolution=resolution)\n",
    "\n",
    "    null_maps = np.zeros((3, resolution, resolution), dtype=np.complex128)\n",
    "    dark_maps = np.zeros((6, resolution, resolution), dtype=np.complex128)\n",
    "    kernel_maps = np.zeros((3, resolution, resolution), dtype=float)\n",
    "\n",
    "    for x in range(resolution):\n",
    "        for y in range(resolution):\n",
    "\n",
    "            new_theta = theta_map[x, y]\n",
    "            new_alpha = alpha_map[x, y]\n",
    "\n",
    "            signals = get_input_fields_njit(\n",
    "                norm=1,\n",
    "                angular_separation=new_theta,\n",
    "                parallactic_angle=new_alpha,\n",
    "                projected_telescope_positions=projected_telescope_positions\n",
    "            )\n",
    "\n",
    "            nulls, darks, _ = kn_fields_njit(\n",
    "                signals, shifts=shifts, shifts_total_opd=shifts_total_opd\n",
    "            )\n",
    "\n",
    "            kernels = np.array([\n",
    "                np.abs(darks[2*i])**2 - np.abs(darks[2*i+1])**2\n",
    "            for i in range(3)])\n",
    "\n",
    "            for i in range(3):\n",
    "                null_maps[i, x, y] = nulls[i]\n",
    "\n",
    "            for i in range(6):\n",
    "                dark_maps[i, x, y] = darks[i]\n",
    "\n",
    "            for i in range(3):\n",
    "                kernel_maps[i, x, y] = kernels[i]\n",
    "\n",
    "    return np.abs(null_maps) ** 2, np.abs(dark_maps) ** 2, kernel_maps\n",
    "\n",
    "\n",
    "def get_transmission_map(\n",
    "    resolution=100,\n",
    "    shifts: u.Quantity = np.zeros(14) * L.unit,\n",
    "    shifts_total_opd: u.Quantity = np.zeros(14) * L.unit,\n",
    "    projected_telescope_positions: u.Quantity = PROJECTED_TELESCOPE_POSITIONS,\n",
    ") -> tuple[np.ndarray[complex], np.ndarray[complex], np.ndarray[float]]:\n",
    "    \"\"\"\n",
    "    Generate all the kernel-nuller transmission maps for a given resolution\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - resolution: Resolution of the map\n",
    "    - shifts: Array of 14 injected OPD\n",
    "    - shifts_total_opd: Array of 14 intrasic OPD\n",
    "    - projected_telescope_positions: Telescope positions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Null outputs map (3 x resolution x resolution)\n",
    "    - Dark outputs map (6 x resolution x resolution)\n",
    "    - Kernel outputs map (3 x resolution x resolution)\n",
    "    \"\"\"\n",
    "\n",
    "    return get_transmission_map_njit(\n",
    "        resolution=resolution,\n",
    "        shifts=shifts.to(L.unit).value,\n",
    "        shifts_total_opd=shifts_total_opd.to(L.unit).value,\n",
    "        projected_telescope_positions=projected_telescope_positions.to(u.m).value,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transmission_maps(\n",
    "    shifts: u.Quantity = np.zeros(14) * L.unit,\n",
    "    shifts_total_opd: u.Quantity = np.zeros(14) * L.unit,\n",
    "    resolution: int = 100,\n",
    "    h=0*u.deg,\n",
    "    l=LATITUDE,\n",
    "    d=DECLINATION,\n",
    "    return_plot=False\n",
    ") -> None:\n",
    "    \n",
    "    projected_telescope_position = project_baseline(TELESCOPE_POSITIONS, h=h, l=l, d=d)\n",
    "    null_maps, dark_maps, kernel_maps = get_transmission_map(resolution, shifts, shifts_total_opd, projected_telescope_positions=projected_telescope_position)\n",
    "    planet_x, planet_y = alpha_theta_to_fov_map_coord(ALPHA, THETA)\n",
    "\n",
    "    _, axs = plt.subplots(2, 6, figsize=(35, 10))\n",
    "\n",
    "    for i in range(3):\n",
    "        im = axs[0, i].imshow(null_maps[i], aspect=\"equal\", cmap=\"hot\", extent=EXTENT)\n",
    "        axs[0, i].set_title(f\"Nuller output {i+1}\")\n",
    "        plt.colorbar(im, ax=axs[0, i])\n",
    "\n",
    "    for i in range(6):\n",
    "        im = axs[1, i].imshow(dark_maps[i], aspect=\"equal\", cmap=\"hot\", extent=EXTENT)\n",
    "        axs[1, i].set_title(f\"Dark output {i+1}\")\n",
    "        axs[1, i].set_aspect(\"equal\")\n",
    "        plt.colorbar(im, ax=axs[1, i])\n",
    "\n",
    "    for i in range(3):\n",
    "        im = axs[0, i + 3].imshow(kernel_maps[i], aspect=\"equal\", cmap=\"bwr\", extent=EXTENT)\n",
    "        axs[0, i + 3].set_title(f\"Kernel {i+1}\")\n",
    "        plt.colorbar(im, ax=axs[0, i + 3])\n",
    "\n",
    "    for ax in axs.flatten():\n",
    "        ax.set_xlabel(r\"$\\theta_x$\" + f\" ({FOV.unit})\")\n",
    "        ax.set_ylabel(r\"$\\theta_y$\" + f\" ({FOV.unit})\")\n",
    "        ax.scatter(0, 0, color=\"yellow\", marker=\"*\", edgecolors=\"black\")\n",
    "        ax.scatter(planet_x, planet_y, color=\"blue\", edgecolors=\"black\")\n",
    "\n",
    "    signals = get_input_fields(norm=1, projected_telescope_positions=projected_telescope_position)\n",
    "    nulls, darks, bright = kn_fields(signals, shifts_total_opd=np.zeros(14) * L.unit)\n",
    "\n",
    "    kernels = np.array([\n",
    "        np.abs(darks[2*i])**2 - np.abs(darks[2*i+1])**2\n",
    "    for i in range(3)])\n",
    "\n",
    "    transmissions = f\"\\nPlanet throughput on bright output: {np.abs(bright)**2*100:.2f}%\"\n",
    "    transmissions += f\"\\nPlanet throughput on null outputs: {' | '.join([f'{np.abs(n)**2*100:.2f}%' for n in nulls])}\"\n",
    "    transmissions += f\"\\nPlanet throughput on dark outputs: {' | '.join([f'{np.abs(d)**2*100:.2f}%' for d in darks])}\"\n",
    "    transmissions += f\"\\nPlanet throughput on kernel outputs: {' | '.join([f'{k*100:.2f}%' for k in kernels])}\"\n",
    "\n",
    "    if return_plot:\n",
    "        plot = BytesIO()\n",
    "        plt.savefig(plot, format='png')\n",
    "        plt.close()\n",
    "        return plot.getvalue(), transmissions\n",
    "    plt.show()\n",
    "    print(transmissions)\n",
    "    \n",
    "def iplot_transmission_maps(resolution=100):\n",
    "\n",
    "    # UI elements\n",
    "    hour_angle_slider = widgets.FloatSlider(value=0, min=-DH.value/2, max=DH.value/2, step=0.01, description='Hour angle:')\n",
    "    latitude_slider = widgets.FloatSlider(value=LATITUDE.to(u.deg).value, min=-90, max=90, step=0.01, description='Latitude:')\n",
    "    declination_slider = widgets.FloatSlider(value=DECLINATION.to(u.deg).value, min=-90, max=90, step=0.01, description='Declination:')\n",
    "    reset = widgets.Button(description=\"Reset values\")\n",
    "    run = widgets.Button(description=\"Run\")\n",
    "    plot = widgets.Image()\n",
    "    transmission = [widgets.Label(), widgets.Label(), widgets.Label(), widgets.Label(), widgets.Label()]\n",
    "\n",
    "    def update_plot(*args):\n",
    "        run.button_style = \"warning\"\n",
    "        \n",
    "        img, txt = plot_transmission_maps(resolution=resolution, h=hour_angle_slider.value*u.deg, l=latitude_slider.value*u.deg, d=declination_slider.value*u.deg, return_plot=True)\n",
    "        plot.value = img\n",
    "        for i, t in enumerate(txt.split(\"\\n\")): \n",
    "            transmission[i].value = t\n",
    "        \n",
    "        run.button_style = \"\"\n",
    "\n",
    "    def reset_values(*args):\n",
    "        hour_angle_slider.value = 0\n",
    "        latitude_slider.value = LATITUDE.to(u.deg).value\n",
    "        declination_slider.value = DECLINATION.to(u.deg).value\n",
    "        run.color = \"blue\"\n",
    "        enable_run()\n",
    "\n",
    "    def enable_run(*args):\n",
    "        run.button_style = \"success\"\n",
    "    \n",
    "    reset.on_click(reset_values)\n",
    "    hour_angle_slider.observe(enable_run)\n",
    "    latitude_slider.observe(enable_run)\n",
    "    declination_slider.observe(enable_run)\n",
    "    run.on_click(update_plot)\n",
    "    display(widgets.VBox([hour_angle_slider, latitude_slider, declination_slider, widgets.HBox([reset, run]), plot, *transmission]))\n",
    "    update_plot()\n",
    "\n",
    "iplot_transmission_maps(resolution=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "# ü™õ **Calibration**\n",
    "\n",
    "</div>\n",
    "\n",
    "## ü´≥ Manual shift controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_shift_control():\n",
    "    step = 1e-20\n",
    "\n",
    "    # Build sliders -----------------------------------------------------------\n",
    "\n",
    "    # Input amplitude\n",
    "    IA_sliders = [\n",
    "        widgets.FloatSlider(\n",
    "            value=1/np.sqrt(4), min=0, max=1, step=step, description=f\"I{i+1}\"\n",
    "        )\n",
    "        for i in range(4)\n",
    "    ]\n",
    "\n",
    "    # Input phase\n",
    "    IP_sliders = [\n",
    "        widgets.FloatSlider(\n",
    "            value=0, min=0, max=L.value, step=step, description=f\"I{i+1}\"\n",
    "        )\n",
    "        for i in range(4)\n",
    "    ]\n",
    "\n",
    "    # Shifter phase\n",
    "    P_sliders = [\n",
    "        widgets.FloatSlider(\n",
    "            value=0, min=0, max=L.value, step=step, description=f\"P{i+1}\"\n",
    "        )\n",
    "        for i in range(14)\n",
    "    ]\n",
    "\n",
    "    # Build GUI ---------------------------------------------------------------\n",
    "\n",
    "    def beam_repr(beam: complex) -> str:\n",
    "        return f\"<b>{np.abs(beam):.2e}</b> * exp(<b>{np.angle(beam)/np.pi:.2f}</b> pi i)\"\n",
    "\n",
    "    inputs = [widgets.HTML(value=f\" \") for _ in range(4)]\n",
    "    null_outputs = [widgets.HTML(value=f\" \") for _ in range(4)]\n",
    "    dark_outputs = [widgets.HTML(value=f\" \") for _ in range(6)]\n",
    "    kernel_outputs = [widgets.HTML(value=f\" \") for _ in range(3)]\n",
    "\n",
    "    def update_gui(*args):\n",
    "\n",
    "        signal = np.array([\n",
    "            IA_sliders[i].value * np.exp(1j * IP_sliders[i].value / L.value * 2 * np.pi)\n",
    "            for i in range(4)\n",
    "        ])\n",
    "\n",
    "        nulls, darks, bright = kn_fields(\n",
    "            beams=signal,\n",
    "            shifts=np.array([x.value for x in P_sliders]) * L.unit,\n",
    "            # shifts_total_opd=np.zeros(14) * L.unit,\n",
    "        )\n",
    "\n",
    "        kernels = np.array([\n",
    "            np.abs(darks[2*i])**2 - np.abs(darks[2*i+1])**2\n",
    "        for i in range(3)])\n",
    "\n",
    "        for i, beam in enumerate(signal):\n",
    "            inputs[i].value = (\n",
    "                f\"<b>Input {i+1} -</b> Amplitude: <code>{beam_repr(beam)}</code> Intensity: <code><b>{np.abs(beam)**2*100:.1f}%</b></code>\"\n",
    "            )\n",
    "        null_outputs[0].value = (\n",
    "            f\"<b>N3a -</b> Amplitude: <code>{beam_repr(bright)}</code> Intensity: <code><b>{np.abs(bright)**2*100:.1f}%</b></code> <b><- Bright channel</b>\"\n",
    "        )\n",
    "        for i, beam in enumerate(nulls):\n",
    "            null_outputs[i + 1].value = (\n",
    "                f\"<b>N{(i-1)//2+4}{['a','b'][(i+1)%2]} -</b> Amplitude: <code>{beam_repr(beam)}</code> Intensity: <code><b>{np.abs(beam)**2*100:.1f}%</b></code>\"\n",
    "            )\n",
    "        for i, beam in enumerate(darks):\n",
    "            dark_outputs[i].value = (\n",
    "                f\"<b>Dark {i+1} -</b> Amplitude: <code>{beam_repr(beam)}</code> Intensity: <code><b>{np.abs(beam)**2*100:.1f}%</b></code>\"\n",
    "            )\n",
    "        for i, beam in enumerate(kernels):\n",
    "            kernel_outputs[i].value = (\n",
    "                f\"<b>Kernel {i+1} -</b> Value: <code>{beam:.2e}</code>\"\n",
    "            )   \n",
    "            \n",
    "        # fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "        phases.value = plot_kn_phase_effect(\n",
    "            inputs=signal,\n",
    "            shifts = np.array([p.value for p in P_sliders])*L.unit,\n",
    "            plot=False\n",
    "            )\n",
    "\n",
    "        # Plot intensities\n",
    "        for i in range(len(signal)):\n",
    "            plt.imshow([[np.abs(signal[i])**2,],], cmap=\"hot\", vmin=0, vmax=np.sum(np.abs(signal)**2))\n",
    "            plt.savefig(fname=f\"img/tmp.png\", format=\"png\")\n",
    "            plt.close()\n",
    "            with open(\"img/tmp.png\", \"rb\") as file:\n",
    "                image = file.read()\n",
    "                photometric_cameras[i].value = image\n",
    "        for i in range(len(nulls)+1):\n",
    "            if i == 0:\n",
    "                plt.imshow([[np.abs(bright)**2,],], cmap=\"hot\", vmin=0, vmax=np.sum(np.abs(nulls)**2) + np.abs(bright)**2)\n",
    "            else:\n",
    "                plt.imshow([[np.abs(nulls[i-1])**2,],], cmap=\"hot\", vmin=0, vmax=np.sum(np.abs(nulls)**2) + np.abs(bright)**2)\n",
    "            plt.savefig(fname=f\"img/tmp.png\", format=\"png\")\n",
    "            plt.close()\n",
    "            with open(\"img/tmp.png\", \"rb\") as file:\n",
    "                image = file.read()\n",
    "                null_cameras[i].value = image\n",
    "        for i in range(len(darks)):\n",
    "            plt.imshow([[np.abs(darks[i])**2,],], cmap=\"hot\", vmin=0, vmax=np.sum(np.abs(darks)**2))\n",
    "            plt.savefig(fname=f\"img/tmp.png\", format=\"png\")\n",
    "            plt.close()\n",
    "            with open(\"img/tmp.png\", \"rb\") as file:\n",
    "                image = file.read()\n",
    "                dark_cameras[i].value = image\n",
    "        for i in range(len(kernels)):\n",
    "            plt.imshow([[kernels[i],],], cmap=\"bwr\", vmin=-np.max(np.abs(kernels)), vmax=np.max(np.abs(kernels)))\n",
    "            plt.savefig(fname=f\"img/tmp.png\", format=\"png\")\n",
    "            plt.close()\n",
    "            with open(\"img/tmp.png\", \"rb\") as file:\n",
    "                image = file.read()\n",
    "                kernel_cameras[i].value = image\n",
    "\n",
    "        os.remove(\"img/tmp.png\")\n",
    "\n",
    "        return bright, darks\n",
    "    \n",
    "    photometric_cameras = [widgets.Image(width=50,height=50) for _ in range(4)]\n",
    "    null_cameras = [widgets.Image(width=50,height=50) for _ in range(4)]\n",
    "    dark_cameras = [widgets.Image(width=50,height=50) for _ in range(6)]\n",
    "    kernel_cameras = [widgets.Image(width=50,height=50) for _ in range(3)]\n",
    "    phases = widgets.Image()\n",
    "\n",
    "    vbox = widgets.VBox(\n",
    "        [\n",
    "            widgets.HTML(\"<h1>Inputs</h1>\"),\n",
    "            widgets.HTML(\"Amplitude:\"),\n",
    "            widgets.HBox(IA_sliders[:4]),\n",
    "            widgets.HTML(\"Phase:\"),\n",
    "            widgets.HBox(IP_sliders[:4]),\n",
    "            *[widgets.HBox([photometric_cameras[i], x]) for i, x in enumerate(inputs)],\n",
    "            widgets.HTML(\"<h1>Phases</h1>\"),\n",
    "            phases,\n",
    "            widgets.HTML(\"<h1>Nuller</h1>\"),\n",
    "            widgets.HBox(P_sliders[:4]),\n",
    "            widgets.HBox(P_sliders[4:8]),\n",
    "            *[widgets.HBox([null_cameras[i], x]) for i, x in enumerate(null_outputs)],\n",
    "            widgets.HTML(\"<h1>Recombiner</h1>\"),\n",
    "            widgets.HBox(P_sliders[8:11]),\n",
    "            widgets.HBox(P_sliders[11:14]),\n",
    "            *[widgets.HBox([dark_cameras[i], x]) for i, x in enumerate(dark_outputs)],\n",
    "            widgets.HTML(\"<h1>Kernels</h1>\"),\n",
    "            *[widgets.HBox([kernel_cameras[i], x]) for i, x in enumerate(kernel_outputs)],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Link sliders to update function ------------------------------------------\n",
    "\n",
    "    for widget in P_sliders:\n",
    "        widget.observe(update_gui, \"value\")\n",
    "    for widget in IA_sliders:\n",
    "        widget.observe(update_gui, \"value\")\n",
    "    for widget in IP_sliders:\n",
    "        widget.observe(update_gui, \"value\")\n",
    "\n",
    "    update_gui()\n",
    "    return vbox\n",
    "\n",
    "manual_shift_control()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß¨ Genetic algorithm\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "in order to get the best shifts to inject to optimize the component performances, I made a genetic algorithme that iteratively mutate a shifter and keep the mutation if it minimize a metric that is defined such as:\n",
    "\n",
    "$$\n",
    "M = \\frac{|K_1| + |K_2| + |K_3|}{|B|^2}\n",
    "$$\n",
    "\n",
    "> **Acknowledgment**\n",
    "> - Romain Laugier for the idea of merging the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate(verbose: bool = False) -> tuple[u.Quantity, dict[str, np.ndarray[float]]]:\n",
    "    \"\"\"\n",
    "    Optimize the phase shifters offsets to maximize the nulling performance\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - kn: Kernel-Nuller object\n",
    "    - beams: List of input beams complex amplitudes\n",
    "    - verbose: Boolean, if True, print the optimization process\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Array of optimized phase shifters offsets\n",
    "    - Dict containing the history of the optimization\n",
    "    \"\"\"\n",
    "\n",
    "    shifts = np.zeros(14) * L.unit\n",
    "    signals = get_input_fields(norm=STAR_FLUX, angular_separation=0*u.mas)\n",
    "\n",
    "    treshold = 1e-6 * L.unit # Minimum shift step size\n",
    "    decay = 1.01  # Decay factor for the step size (delta /= decay)\n",
    "\n",
    "    # Shifters that contribute to redirecting light to the bright output\n",
    "    # p1 = [2,3,4,5,7]\n",
    "    p1 = [1, 2, 3, 4, 5, 7]\n",
    "    # p1 = [2, 4, 7]\n",
    "    # p1 = [2, 3, 4]\n",
    "\n",
    "    # Shifters that contribute to the symmetry of the dark outputs\n",
    "    # p2 = [6,8,11,13,14]\n",
    "    p2 = [6, 8, 9, 10, 11, 12, 13, 14]\n",
    "    # p2 = [8, 11, 13, 14]\n",
    "    # p2 = [6, 9, 10, 12]\n",
    "\n",
    "    # History of the optimization\n",
    "    bright_history = []\n",
    "    asymmetry_history = []\n",
    "    metric_history = []\n",
    "    shifters_history = []\n",
    "\n",
    "    delta = L / 4\n",
    "    while delta > treshold:\n",
    "\n",
    "        if verbose:\n",
    "            print(color.black(color.on_red(f\"--- New iteration ---\")), f\"Delta={delta:.2e}\")\n",
    "\n",
    "        for p in p1 + p2:\n",
    "            log = \"\"\n",
    "\n",
    "            # Step vector\n",
    "            step = np.zeros(14) * L.unit\n",
    "            step[p - 1] = delta\n",
    "\n",
    "            # Apply the step\n",
    "            _, kernels_old, bright_old = kn(beams=signals, shifts=shifts)\n",
    "            _, kernels_pos, bright_pos = kn(beams=signals, shifts=shifts + step)\n",
    "            _, kernels_neg, bright_neg = kn(beams=signals, shifts=shifts - step)\n",
    "\n",
    "            # Total Kernels relative intensity\n",
    "            kernels_neg = np.sum(np.abs(kernels_neg)) / (STAR_FLUX * DT)\n",
    "            kernels_old = np.sum(np.abs(kernels_old)) / (STAR_FLUX * DT)\n",
    "            kernels_pos = np.sum(np.abs(kernels_pos)) / (STAR_FLUX * DT)\n",
    "\n",
    "            # Birght relative intensity\n",
    "            bright_neg /= STAR_FLUX * DT\n",
    "            bright_old /= STAR_FLUX * DT\n",
    "            bright_pos /= STAR_FLUX * DT\n",
    "\n",
    "            metric_neg =  kernels_neg / bright_neg\n",
    "            metric_old =  kernels_old / bright_old\n",
    "            metric_pos =  kernels_pos / bright_pos\n",
    "\n",
    "            # Save the history\n",
    "            bright_history.append(bright_old)\n",
    "            asymmetry_history.append(kernels_old)\n",
    "            metric_history.append(metric_old)\n",
    "            shifters_history.append(np.copy(shifts))\n",
    "\n",
    "            metric = True\n",
    "\n",
    "            if not metric:\n",
    "                # Maximize the bright metric for group 1 shifters\n",
    "                if p in p1:\n",
    "                    log += \"Shift \" + color.black(color.on_lightgrey(f\"{p}\")) + \" Bright: \" + color.black(color.on_green(f\"{bright_neg:.2e} | {bright_old:.2e} | {bright_pos:.2e}\")) + \" -> \"\n",
    "\n",
    "                    if bright_pos > bright_old and bright_pos > bright_neg:\n",
    "                        log += color.black(color.on_green(\" + \"))\n",
    "                        shifts += step\n",
    "                    elif bright_neg > bright_old and bright_neg > bright_pos:\n",
    "                        log += color.black(color.on_green(\" - \"))\n",
    "                        shifts -= step\n",
    "                    else:\n",
    "                        log += color.black(color.on_green(\" = \"))\n",
    "\n",
    "                # Minimize the asymmetry metric for group 2 shifters\n",
    "                else:\n",
    "                    log += \"Shift \" + color.black(color.on_lightgrey(f\"{p}\")) + \" Asymmetry:  \" + color.black(color.on_blue(f\"{kernels_neg:.2e} | {kernels_old:.2e} | {kernels_pos:.2e}\")) + \" -> \"\n",
    "\n",
    "                    if kernels_pos < kernels_old and kernels_pos < kernels_neg:\n",
    "                        shifts += step\n",
    "                        log += color.black(color.on_blue(\" + \"))\n",
    "                    elif kernels_neg < kernels_old and kernels_neg < kernels_pos:\n",
    "                        shifts -= step\n",
    "                        log += color.black(color.on_blue(\" - \"))\n",
    "                    else:\n",
    "                        log += color.black(color.on_blue(\" = \"))\n",
    "\n",
    "            else: \n",
    "                log += \"Shift \" + color.black(color.on_lightgrey(f\"{p}\")) + \" Metric:  \" + color.black(color.on_purple(f\"{metric_neg:.2e} | {metric_old:.2e} | {metric_pos:.2e}\")) + \" -> \"\n",
    "\n",
    "                if metric_pos < metric_old and metric_pos < metric_neg:\n",
    "                    shifts += step\n",
    "                    log += color.black(color.on_purple(\" + \"))\n",
    "                elif metric_neg < metric_old and metric_neg < metric_pos:\n",
    "                    shifts -= step\n",
    "                    log += color.black(color.on_purple(\" - \"))\n",
    "                else:\n",
    "                    log += color.black(color.on_purple(\" = \"))\n",
    "            \n",
    "            if verbose:\n",
    "                print(log)\n",
    "\n",
    "        delta /= decay\n",
    "\n",
    "    return bound_phase(shifts), {\n",
    "        \"bright\": np.array(bright_history),\n",
    "        \"asymmetry\": np.array(asymmetry_history),\n",
    "        \"shifters\": np.array(shifters_history),\n",
    "    }\n",
    "\n",
    "CALIBRATED_SHIFTS, CALIBRATION_HISTORY = calibrate(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimization_history():\n",
    "    bright_evol, dark_asymmetry_evol, shifts_evol = CALIBRATION_HISTORY[\"bright\"], CALIBRATION_HISTORY[\"asymmetry\"], CALIBRATION_HISTORY[\"shifters\"]\n",
    "\n",
    "    _, axs = plt.subplots(4,1, figsize=(15,20))\n",
    "\n",
    "    axs[0].plot(bright_evol)\n",
    "    axs[0].set_xlabel(\"Number of iterations\")\n",
    "    axs[0].set_ylabel(\"Bright throughput (%)\")\n",
    "    axs[0].set_yscale(\"log\")\n",
    "    axs[0].set_title(\"Optimization of the bright output\")\n",
    "\n",
    "    axs[1].plot(dark_asymmetry_evol)\n",
    "    axs[1].set_xlabel(\"Number of iterations\")\n",
    "    axs[1].set_ylabel(\"Kernels throughput (%)\")\n",
    "    axs[1].set_yscale(\"log\")\n",
    "    axs[1].set_title(\"Optimization of the kernels\")\n",
    "\n",
    "    axs[2].plot(dark_asymmetry_evol)\n",
    "    axs[2].set_xlabel(\"Number of iterations\")\n",
    "    axs[2].set_ylabel(\"Matric\")\n",
    "    axs[2].set_yscale(\"log\")\n",
    "    axs[2].set_title(\"Optimization of the metric\")\n",
    "\n",
    "    print(np.mean(dark_asymmetry_evol[-2000:]))\n",
    "\n",
    "    for i in range(shifts_evol.shape[1]):\n",
    "        axs[3].plot(shifts_evol[:,i], label=f\"Shifter {i+1}\")\n",
    "    axs[3].set_xlabel(\"Number of iterations\")\n",
    "    axs[3].set_ylabel(\"Phase shift\")\n",
    "    axs[3].set_yscale(\"linear\")\n",
    "    axs[3].set_title(\"Convergeance of the phase shifters\")\n",
    "    axs[3].legend(loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_optimization_history()\n",
    "plot_kn_phase_effect()\n",
    "plot_kn_phase_effect(shifts=CALIBRATED_SHIFTS)\n",
    "plot_transmission_maps(shifts=CALIBRATED_SHIFTS, shifts_total_opd=SHIFTS_TOTAL_OPD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reliability (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_emprical_proof():\n",
    "\n",
    "    _, axs = plt.subplots(2, 7, figsize=(20, 5))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    _, axs2 = plt.subplots(2, 7, figsize=(20, 5))\n",
    "    axs2 = axs2.flatten()\n",
    "\n",
    "    for _ in range(100):\n",
    "        shifts_total_opd = np.array(np.random.uniform(0, L.value, 14)) * L.unit\n",
    "        calibrated_shifts, _ = calibrate(shifts_total_opd=shifts_total_opd)\n",
    "\n",
    "        E = bound_phase(shifts_total_opd)\n",
    "        P = bound_phase(calibrated_shifts)\n",
    "\n",
    "        for i in range(14):\n",
    "            axs[i].scatter(E[i], P[i], color='blue', s=1)\n",
    "            axs[i].set_xlabel(\"Introduced error\")\n",
    "            axs[i].set_ylabel(\"Optimized shift\")\n",
    "            axs[i].set_title(f\"P{i+1}\")\n",
    "\n",
    "        def bound(p):\n",
    "            return bound_phase(p)\n",
    "\n",
    "        axs2[0].scatter(bound(E[0] - E[1]), bound(P[0] - P[1]), color='blue', s=1)\n",
    "        axs2[0].set_title(\"P1-P2\")\n",
    "        axs2[1].scatter(bound(E[2] - E[3]), bound(P[2] - P[3]), color='blue', s=1)\n",
    "        axs2[1].set_title(\"P3-P4\")\n",
    "        axs2[2].scatter(bound(E[4] - E[6]), bound(P[4] - P[6]), color='blue', s=1)\n",
    "        axs2[2].set_title(\"P5 - P7\")\n",
    "        axs2[3].scatter(bound(E[5] - E[7]), bound(P[5] - P[7]), color='blue', s=1)\n",
    "        axs2[3].set_title(\"P6 - P8\")\n",
    "        axs2[4].scatter(bound(E[8] - E[10]), bound(P[8] - P[10]), color='blue', s=1)\n",
    "        axs2[4].set_title(\"P9 - P11\")\n",
    "        axs2[5].scatter(bound(E[9] - E[12]), bound(P[9] - P[12]), color='blue', s=1)\n",
    "        axs2[5].set_title(\"P10 - P13\")\n",
    "        axs2[6].scatter(bound(E[11] - E[13]), bound(P[11] - P[13]), color='blue', s=1)\n",
    "        axs2[6].set_title(\"P12 - P14\")\n",
    "\n",
    "        axs2[7].scatter(bound((E[0] + E[1]) - (E[2] + E[3])), bound((P[0] + P[1]) - (P[2] + P[3])), color='blue', s=1)\n",
    "        axs2[7].set_title(\"(P1-P2)*P5 - (P3-P4)*P7\")\n",
    "\n",
    "        axs2[8].scatter((E[0] + E[1])/2 * E[4] - ((E[2] + E[3])/2 * E[6]), ((P[0] + P[1])/2 * P[4]) - ((P[2] + P[3])/2 * P[6]), color='blue', s=1)\n",
    "        axs2[8].set_title(\"(P1+P2)/2*P5 - (P3+P4)/2*P7\")\n",
    "\n",
    "        for i in range(14):\n",
    "            axs2[i].set_xlabel(\"Introduced error\")\n",
    "            axs2[i].set_ylabel(\"Optimized shift\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# optimization_emprical_proof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Machine Learning Approach\n",
    "\n",
    "Another approach to retrieve the correct shifts inject is to use machine learning techniques. There is several ways to do so. Here we will focus a supervised dense neural network. To do so, we will have to build a dataset.\n",
    "\n",
    "As the solutions are degenerated, we will not ask the network to predict the best shift to inject, but we will ask it to predict the shfit aberrations instead. From these aberation, we are able to determine a solution for the shifts to inject.\n",
    "\n",
    "As input of the network, we need to give enough information to caracterize the parameter space. The most straightforward approach would be to create a grid in the parameter space and give the kenrel outputs for each of the point in these grid.\n",
    "\n",
    "Unfortunately, we work in a parameter space of 14 dimensions which is too large to be covered by a grid. A solution is to consider only the vectors that form the cardinal basis of this parameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_grid(N, D, a, b):\n",
    "    \"\"\"\n",
    "    Generate a list of points forming a grid in a parameter space.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - N: Resolution of the grid (point per axes)\n",
    "    - D: Dimension of the space parameter\n",
    "    - a: Minimum value of the space parameter\n",
    "    - b: Maximum value of the space parameter\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - An array of vectors describing a point in the parameter space\n",
    "    \"\"\"\n",
    "    return np.array([a + (b-a) * (((x // N**np.arange(D,dtype=float)) % N)/N) for x in range(N**D)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_basis(D, b=1):\n",
    "    \"\"\"\n",
    "    Return the basis vectors of the parameter space (+ the null vector)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - D: Dimension of the space parameter\n",
    "    - b: Norm of the basis vector (default=1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - An array of vectors describing a point in the parameter space\n",
    "    \"\"\"\n",
    "\n",
    "    vectors = np.zeros((D+1,D))\n",
    "    for i in range(D):\n",
    "        vectors[i+1,i] = b\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_basis_2p(D, b=1):\n",
    "    \"\"\"\n",
    "    Return the basis vectors of the parameter space (+ the null vector)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - D: Dimension of the space parameter\n",
    "    - b: Norm of the basis vector (default=1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - An array of vectors describing a point in the parameter space\n",
    "    \"\"\"\n",
    "\n",
    "    vectors = np.zeros((2*D+1,D))\n",
    "    for i in range(D):\n",
    "        vectors[2*i+1,i] = b\n",
    "        vectors[2*i+2,i] = 2*b\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 217)\n"
     ]
    }
   ],
   "source": [
    "def get_dataset(size=1000):\n",
    "    # grid_points = parameter_grid(2, 14, 0, 1.65)\n",
    "    # grid_points = parameter_basis(14, 1.65/2)\n",
    "    grid_points = parameter_basis_2p(14, 1.65/3)\n",
    "    vector_len = len(grid_points)*7 + 14\n",
    "    dataset = np.empty((size, vector_len))\n",
    "\n",
    "    for v in range(size):\n",
    "\n",
    "        shifts_total_opd = np.random.uniform(0, 1, 14) * L/10\n",
    "        vector = np.empty(vector_len)\n",
    "\n",
    "        for p, point in enumerate(grid_points):\n",
    "            _, darks, bright = kn_fields_njit(beams=STAR_SIGNALS, shifts=point, shifts_total_opd=shifts_total_opd)\n",
    "\n",
    "            vector[p*7:p*7+6] = np.abs(darks)**2\n",
    "            vector[p*7+6] = np.abs(bright)**2\n",
    "\n",
    "        vector[-14:] = shifts_total_opd\n",
    "        dataset[v] = vector\n",
    "\n",
    "    return dataset\n",
    "\n",
    "DATASET = get_dataset(10_000)\n",
    "print(DATASET.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2114)\n"
     ]
    }
   ],
   "source": [
    "def get_random_dataset(size=1000):\n",
    "\n",
    "    nb_points = 100\n",
    "\n",
    "    i_len = (7+14)\n",
    "    o_len = 14\n",
    "\n",
    "    vector_len = nb_points*i_len + o_len\n",
    "    dataset = np.empty((size, vector_len))\n",
    "\n",
    "    pv=0\n",
    "    for v in range(size):\n",
    "\n",
    "        if (nv := v*100//size) > pv:\n",
    "            print(nv, \"%\", end='\\r')\n",
    "            pv = nv\n",
    "\n",
    "        shifts_total_opd = np.random.uniform(0, 1, 14) * L/10\n",
    "        vector = np.empty(vector_len)\n",
    "\n",
    "        for p in range(nb_points):\n",
    "            shifts = np.random.uniform(0, L.value, size=14)\n",
    "            _, darks, bright = kn_fields_njit(beams=STAR_SIGNALS, shifts=shifts, shifts_total_opd=shifts_total_opd)\n",
    "\n",
    "            vector[p*i_len:(p+1)*i_len] = np.concatenate([shifts, np.abs(darks)**2, [np.abs(bright)**2]])\n",
    "\n",
    "        vector[-14:] = shifts_total_opd\n",
    "        dataset[v] = vector\n",
    "\n",
    "    return dataset\n",
    "\n",
    "DATASET = get_random_dataset(10_000)\n",
    "print(DATASET.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET[:,-14:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2100</span>)           ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">268,928</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ Input (\u001b[38;5;33mInputLayer\u001b[0m)              ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2100\u001b[0m)           ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Dense_1 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            ‚îÇ       \u001b[38;5;34m268,928\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Dense_2 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             ‚îÇ         \u001b[38;5;34m8,256\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Dense_3 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             ‚îÇ         \u001b[38;5;34m2,080\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ Output (\u001b[38;5;33mDense\u001b[0m)                  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             ‚îÇ           \u001b[38;5;34m462\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">279,726</span> (1.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m279,726\u001b[0m (1.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">279,726</span> (1.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m279,726\u001b[0m (1.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_model(input_shape):\n",
    "    i = tf.keras.Input(shape=(input_shape,), name='Input')\n",
    "    # x = tf.keras.layers.Normalization(axis=None, mean=np.mean(DATASET[:,:-14]), variance=np.std(DATASET[:,:-14]), invert=False, name=\"Normalization\")(i)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name='Dense_1')(i)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='Dense_2')(x)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu', name='Dense_3')(x)\n",
    "    o = tf.keras.layers.Dense(14, activation='relu', name='Output')(x)\n",
    "    # o = tf.keras.layers.Normalization(axis=None, mean=np.mean(DATASET[:,-14:]), variance=np.std(DATASET[:,-14:]), invert=True, name=\"Denormalization\")(x)\n",
    "    return tf.keras.Model(inputs=i, outputs=o)\n",
    "\n",
    "MODEL = get_model(input_shape=DATASET.shape[1]-14)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "MODEL.compile(optimizer=optimizer, loss='mse')\n",
    "MODEL.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2114) (10000, 2100) (10000, 14)\n",
      "Epoch 1/10\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 1842405678514176.0000 - val_loss: 31050835165184.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 15376440098816.0000 - val_loss: 7627935842304.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2545787338752.0000 - val_loss: 3280564912128.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 800728416256.0000 - val_loss: 2310087114752.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 140634439680.0000 - val_loss: 1624657362944.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 20891635712.0000 - val_loss: 1666908422144.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 492136416.0000 - val_loss: 1455152824320.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 15036564.0000 - val_loss: 1302984654848.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.0091 - val_loss: 1302984654848.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.0091 - val_loss: 1302984654848.0000\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    X = DATASET[:, :-14]\n",
    "    Y = DATASET[:, -14:]\n",
    "\n",
    "    print(DATASET.shape, X.shape, Y.shape)\n",
    "\n",
    "    return MODEL.fit(X, Y, epochs=10, batch_size=5, validation_split=0.2, )\n",
    "\n",
    "history = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_SET = get_dataset(size=10)\n",
    "# X = TEST_SET[:, :-14]\n",
    "# Y = TEST_SET[:, -14:]\n",
    "\n",
    "# PREDICTIONS = MODEL.predict(X)\n",
    "# print(X)\n",
    "# print(PREDICTIONS)\n",
    "\n",
    "# # print(Y)\n",
    "# # print(PREDICTIONS)\n",
    "\n",
    "# cpt = 0\n",
    "# for i in range(10):\n",
    "#     for j in range(len(Y[i])):\n",
    "#         # print(f\"Shifter {j}: E = {Y[i][j]:.2f}\", f\"P = {PREDICTIONS[i][j]:.2f}\")\n",
    "#         plt.scatter(Y[i][j], PREDICTIONS[i][j])\n",
    "#         cpt += 1\n",
    "#     #     if cpt > 1:break\n",
    "#     # if cpt > 1:break\n",
    "\n",
    "# plt.xlabel(\"Expectations\")\n",
    "# plt.ylabel(\"Preditions\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "[[4.63598434e-01 5.65847884e-01 1.13816360e-01 ... 3.90654135e+08\n",
      "  2.81533142e+08 2.21551287e+09]\n",
      " [1.38336436e+00 1.61787374e+00 1.10541963e+00 ... 2.50390074e+07\n",
      "  2.03361422e+08 6.59222608e+08]\n",
      " [1.52141271e+00 8.54847866e-01 1.44104351e+00 ... 7.27891030e+08\n",
      "  1.25325309e+08 6.63199276e+08]\n",
      " ...\n",
      " [1.62144710e+00 4.33470165e-01 5.97593872e-01 ... 2.27238518e+09\n",
      "  4.60025589e+08 3.04469884e+08]\n",
      " [5.87098805e-01 1.31370954e+00 5.12923627e-01 ... 1.36291109e+09\n",
      "  1.29880066e+09 3.57482869e+08]\n",
      " [3.65698062e-01 1.04170491e+00 3.87627398e-01 ... 1.10881872e+09\n",
      "  9.99817501e+08 7.95277856e+08]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TEST_SET = get_random_dataset(size=10)\n",
    "X = TEST_SET[:, :-14]\n",
    "Y = TEST_SET[:, -14:]\n",
    "\n",
    "PREDICTIONS = MODEL.predict(X)\n",
    "print(X)\n",
    "print(PREDICTIONS)\n",
    "\n",
    "# print(Y)\n",
    "# print(PREDICTIONS)\n",
    "\n",
    "cpt = 0\n",
    "for i in range(10):\n",
    "    for j in range(len(Y[i])):\n",
    "        # print(f\"Shifter {j}: E = {Y[i][j]:.2f}\", f\"P = {PREDICTIONS[i][j]:.2f}\")\n",
    "        plt.scatter(Y[i][j], PREDICTIONS[i][j])\n",
    "        cpt += 1\n",
    "    #     if cpt > 1:break\n",
    "    # if cpt > 1:break\n",
    "\n",
    "plt.xlabel(\"Expectations\")\n",
    "plt.ylabel(\"Preditions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≠ Shifters correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(\n",
    "    scan_on,\n",
    "    restricted: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Scan the parameter space and plot the null depths for each parameter\n",
    "    combination.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - kn: An instance of the KernelNuller class.\n",
    "    - beams: A list of 2D arrays, each representing a beam.\n",
    "    - optimized_parameters: A list of 14 floats, the optimized parameters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    # Scan shift power parameter space\n",
    "    scan = np.linspace(0, L.value, 101, endpoint=True) * L.unit\n",
    "\n",
    "    # Initialize the maps\n",
    "    nulls_map = np.zeros((3, len(scan), len(scan)))\n",
    "    darks_map = np.zeros((6, len(scan), len(scan)))\n",
    "    kernels_map = np.zeros((3, len(scan), len(scan)))\n",
    "    bright_map = np.zeros((len(scan), len(scan)))\n",
    "\n",
    "    # Create the figure\n",
    "    _, axs = plt.subplots(3, 5, figsize=(30, 15))\n",
    "\n",
    "    # Consider only errors & correction on the shifter that are being scanned\n",
    "    if restricted:\n",
    "        shifts = np.zeros(14) * L.unit\n",
    "        shifts_total_opd = np.zeros(14) * L.unit\n",
    "        shifts_total_opd[scan_on[0] - 1] = SHIFTS_TOTAL_OPD[scan_on[0] - 1]\n",
    "        shifts_total_opd[scan_on[1] - 1] = SHIFTS_TOTAL_OPD[scan_on[1] - 1]\n",
    "\n",
    "    # Consider all shifter errors & corrections\n",
    "    else:\n",
    "        shifts = CALIBRATED_SHIFTS.copy()\n",
    "        shifts_total_opd = SHIFTS_TOTAL_OPD.copy()\n",
    "\n",
    "    signals = get_input_fields(angular_separation=0*u.mas)\n",
    "\n",
    "    for i, scan1 in enumerate(scan):\n",
    "        for j, scan2 in enumerate(scan):\n",
    "            shifts[scan_on[0] - 1] = scan1\n",
    "            shifts[scan_on[1] - 1] = scan2\n",
    "\n",
    "            nulls, darks, bright = kn_fields(beams=signals, shifts=shifts, shifts_total_opd=shifts_total_opd)\n",
    "            \n",
    "            kernels = np.array([\n",
    "                    np.abs(darks[2*i])**2 - np.abs(darks[2*i+1])**2\n",
    "                for i in range(3)])\n",
    "\n",
    "            for k, null in enumerate(nulls):\n",
    "                nulls_map[k, i, j] = np.abs(null)**2\n",
    "            for k, dark in enumerate(darks):\n",
    "                darks_map[k, i, j] = np.abs(dark)**2\n",
    "            for k, kernel in enumerate(kernels):\n",
    "                kernels_map[k, i, j] = kernel\n",
    "            bright_map[i, j] = np.abs(bright)**2\n",
    "\n",
    "    for k in range(3):\n",
    "        p = axs[k, 0]\n",
    "        p.set_title(f\"Null {k+1}\")\n",
    "        im = p.imshow(\n",
    "            nulls_map[k],\n",
    "            extent=[0, L.value, 0, L.value],\n",
    "            vmin=np.min(nulls_map),\n",
    "            vmax=np.max(nulls_map),\n",
    "        )\n",
    "        p.scatter(\n",
    "            CALIBRATED_SHIFTS[scan_on[1] - 1],\n",
    "            CALIBRATED_SHIFTS[scan_on[0] - 1],\n",
    "            color=\"red\",\n",
    "            edgecolors=\"white\",\n",
    "            s=100,\n",
    "        )\n",
    "        p.scatter(\n",
    "            IDEAL_SHIFTS[scan_on[1] - 1],\n",
    "            IDEAL_SHIFTS[scan_on[0] - 1],\n",
    "            color=\"green\",\n",
    "            edgecolors=\"white\",\n",
    "            s=100,\n",
    "        )\n",
    "        p.set_xlabel(f\"Parameter {scan_on[1]}\")\n",
    "        p.set_ylabel(f\"Parameter {scan_on[0]}\")\n",
    "        plt.colorbar(im)\n",
    "\n",
    "    for k in range(6):\n",
    "        p = axs[k // 2, k % 2 + 1]\n",
    "        p.set_title(f\"Dark {k+1}\")\n",
    "        im = p.imshow(\n",
    "            darks_map[k],\n",
    "            extent=[0, L.value, 0, L.value],\n",
    "            vmin=np.min(darks_map),\n",
    "            vmax=np.max(darks_map),\n",
    "            cmap=\"hot\",\n",
    "        )\n",
    "        p.scatter(\n",
    "            CALIBRATED_SHIFTS[scan_on[1] - 1],\n",
    "            CALIBRATED_SHIFTS[scan_on[0] - 1],\n",
    "            color=\"red\",\n",
    "            edgecolors=\"white\",\n",
    "            s=100,\n",
    "        )\n",
    "        p.scatter(\n",
    "            IDEAL_SHIFTS[scan_on[1] - 1],\n",
    "            IDEAL_SHIFTS[scan_on[0] - 1],\n",
    "            color=\"green\",\n",
    "            edgecolors=\"white\",\n",
    "            s=100,\n",
    "        )\n",
    "        p.set_xlabel(f\"Parameter {scan_on[1]}\")\n",
    "        p.set_ylabel(f\"Parameter {scan_on[0]}\")\n",
    "        plt.colorbar(im)\n",
    "\n",
    "    for k in range(3):\n",
    "        p = axs[k, 3]\n",
    "        p.set_title(f\"Kernel {k+1}\")\n",
    "        im = p.imshow(\n",
    "            kernels_map[k],\n",
    "            extent=[0, L.value, 0, L.value],\n",
    "            vmin=np.min(kernels_map),\n",
    "            vmax=np.max(kernels_map),\n",
    "            cmap=\"bwr\",\n",
    "        )\n",
    "        p.scatter(\n",
    "            CALIBRATED_SHIFTS[scan_on[1] - 1],\n",
    "            CALIBRATED_SHIFTS[scan_on[0] - 1],\n",
    "            color=\"red\",\n",
    "            edgecolors=\"white\",\n",
    "            s=100,\n",
    "        )\n",
    "        p.scatter(\n",
    "            IDEAL_SHIFTS[scan_on[1] - 1],\n",
    "            IDEAL_SHIFTS[scan_on[0] - 1],\n",
    "            color=\"green\",\n",
    "            edgecolors=\"white\",\n",
    "            s=100,\n",
    "        )\n",
    "        p.set_xlabel(f\"Parameter {scan_on[1]}\")\n",
    "        p.set_ylabel(f\"Parameter {scan_on[0]}\")\n",
    "        plt.colorbar(im)\n",
    "\n",
    "    p = axs[1, 4]\n",
    "    p.set_title(f\"Bright\")\n",
    "    im = p.imshow(bright_map, extent=[0, L.value, 0, L.value], cmap=\"gray\")\n",
    "    p.scatter(\n",
    "        CALIBRATED_SHIFTS[scan_on[1] - 1],\n",
    "        CALIBRATED_SHIFTS[scan_on[0] - 1],\n",
    "        color=\"red\",\n",
    "        edgecolors=\"white\",\n",
    "        s=100,\n",
    "    )\n",
    "    p.scatter(\n",
    "        IDEAL_SHIFTS[scan_on[1] - 1],\n",
    "        IDEAL_SHIFTS[scan_on[0] - 1],\n",
    "        color=\"green\",\n",
    "        edgecolors=\"white\",\n",
    "        s=100,\n",
    "    )\n",
    "    p.set_xlabel(f\"Parameter {scan_on[1]}\")\n",
    "    p.set_ylabel(f\"Parameter {scan_on[0]}\")\n",
    "    plt.colorbar(im)\n",
    "\n",
    "    axs[0, 4].axis(\"off\")\n",
    "    axs[2, 4].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "scan_on = (1, 2)\n",
    "scan(scan_on=scan_on, restricted=True)\n",
    "scan(scan_on=scan_on, restricted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "# ‚öôÔ∏è **Data generation**\n",
    "\n",
    "</div>\n",
    "\n",
    "## üü® Single observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit()\n",
    "def generate_one_distrib_njit(\n",
    "    N: int = 1000,  # Number of observations\n",
    "    star_signals: np.array = STAR_SIGNALS,  # Star signals\n",
    "    planet_signals: np.array = PLANET_SIGNALS,  # Planet signals\n",
    "    shifts: np.array = CALIBRATED_SHIFTS.to(L.unit).value,  # Shifts to apply\n",
    "    shifts_total_opd: np.array = SHIFTS_TOTAL_OPD.to(L.unit).value,  # Shifts error\n",
    "    input_ce_rms: float = INPUT_CE_RMS.to(L.unit).value,  # Input OPD RMS\n",
    "    wavelength: float = L.value,  # Wavelength\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulate several observation of the Kernel-Nuller in the same conditions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - N: Number of observations\n",
    "    - star_signals: Star signals\n",
    "    - planet_signals: Planet signals\n",
    "    - shifts: Shifts to apply\n",
    "    - shifts_total_opd: Shifts error\n",
    "    - input_ce_rms: Input OPD RMS\n",
    "    - wavelength: Wavelength\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Darks outputs without planet (6 x N)\n",
    "    - Darks outputs with planet (6 x N)\n",
    "    - Kernels outputs without planet (3 x N)\n",
    "    - Kernels outputs with planet (3 x N)\n",
    "    \"\"\"\n",
    "\n",
    "    darks_dist_so = np.empty((6, N))\n",
    "    darks_dist_wp = np.empty((6, N))\n",
    "    kernels_dist_so = np.empty((3, N))\n",
    "    kernels_dist_wp = np.empty((3, N))\n",
    "\n",
    "    for i in range(N):\n",
    "\n",
    "        noise = random_normal(0, input_ce_rms, 4)\n",
    "\n",
    "        noised_star_signals = phase_shift_njit(star_signals, noise, wavelength)\n",
    "        noised_planet_signals = phase_shift_njit(planet_signals, noise, wavelength)\n",
    "\n",
    "        darks_so, kernels_so, _ = kn_njit(noised_star_signals, shifts, shifts_total_opd, wavelength)\n",
    "        darks_wp, kernels_wp, _ = kn_njit(noised_planet_signals, shifts, shifts_total_opd, wavelength)\n",
    "\n",
    "        darks_dist_so[:, i] = darks_so\n",
    "        darks_dist_wp[:, i] = darks_wp + darks_so\n",
    "        kernels_dist_so[:, i] = kernels_so\n",
    "        kernels_dist_wp[:, i] = kernels_wp + kernels_so\n",
    "\n",
    "    return (\n",
    "        darks_dist_so,\n",
    "        darks_dist_wp,\n",
    "        kernels_dist_so,\n",
    "        kernels_dist_wp,\n",
    "    )\n",
    "\n",
    "# User-friendly interface (Numba can't manage dicts with unconsistent data)\n",
    "def generate_one_distrib(\n",
    "    N: int = 1000,\n",
    "    star_signals: np.ndarray[complex] = STAR_SIGNALS,\n",
    "    planet_signals: np.ndarray[complex] = PLANET_SIGNALS,\n",
    "    shifts: u.Quantity = CALIBRATED_SHIFTS,\n",
    "    shifts_total_opd: u.Quantity = SHIFTS_TOTAL_OPD,\n",
    "    input_ce_rms: u.Quantity = INPUT_CE_RMS,\n",
    "    wavelength: u.Quantity = L,\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulate several observation of the Kernel-Nuller in the same conditions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - N: Number of observations\n",
    "    - star_signals: Star signals\n",
    "    - planet_signals: Planet signals\n",
    "    - shifts: Shifts to apply\n",
    "    - shifts_total_opd: Shifts error\n",
    "    - input_ce_rms: Input OPD RMS\n",
    "    - wavelength: Wavelength\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Dictionary containing:\n",
    "        - \"darks_so\" dark outpus with star only (6 x N)\n",
    "        - \"darks_wp\" dark outpus with star and planet (6 x N)\n",
    "        - \"kernels_so\" kernel outpus with star only (3 x N) (with photon noise)\n",
    "        - \"kernels_wp\" kernel outpus with star and planet (3 x N) (with photon noise)\n",
    "    \"\"\"\n",
    "\n",
    "    outputs = generate_one_distrib_njit(\n",
    "        N,\n",
    "        star_signals,\n",
    "        planet_signals,\n",
    "        shifts.to(wavelength.unit).value,\n",
    "        shifts_total_opd.to(wavelength.unit).value,\n",
    "        input_ce_rms.to(wavelength.unit).value,\n",
    "        wavelength.value,\n",
    "    )\n",
    "    return {\n",
    "        \"darks_so\": outputs[0],\n",
    "        \"darks_wp\": outputs[1],\n",
    "        \"kernels_so\": outputs[2],\n",
    "        \"kernels_wp\": outputs[3],\n",
    "    }\n",
    "\n",
    "IDEAL_DISTS = generate_one_distrib(\n",
    "    shifts=np.zeros(14)*L.unit,\n",
    "    shifts_total_opd=np.zeros(14)*L.unit\n",
    ")\n",
    "\n",
    "CALIBRATED_DISTS = generate_one_distrib()\n",
    "\n",
    "PERTURBED_DISTS = generate_one_distrib(\n",
    "    shifts=np.zeros(14)*L.unit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üü° Parallactic diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hour_diversity_data(h_range=H_RANGE):\n",
    "    \"\"\"\n",
    "    Generate the data for the hour diversity study.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - h_range: Range of hour angles\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - Array of data for each kernel (3 x len(h_range))\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.zeros((3, len(h_range)))\n",
    "    for i, h in enumerate(h_range):\n",
    "\n",
    "        dists = generate_one_distrib()\n",
    "\n",
    "        for k in range(3):\n",
    "            data[k, i] = np.median(dists['kernels_wp'][k])\n",
    "\n",
    "    return data\n",
    "\n",
    "HOUR_DIVERSITY_DATA = generate_hour_diversity_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "# üîé **Data analysis**\n",
    "\n",
    "</div>\n",
    "\n",
    "## üìä Output distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(calibrated_dists=CALIBRATED_DISTS, ideal_dists=IDEAL_DISTS, perturbed_dists=PERTURBED_DISTS):\n",
    "\n",
    "    null_outputs = ['N3b', 'N4a', 'N4b']\n",
    "\n",
    "    bins = 300\n",
    "\n",
    "    # Dark ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        \n",
    "    fig, axs = plt.subplots(6, 1, figsize=(15, 30))\n",
    "    for i in range(6):\n",
    "        ax = axs[i]\n",
    "\n",
    "        ax.hist(calibrated_dists['darks_so'][i], bins=bins, color='red', label=f\"Star only (calibrated)\", alpha=0.5, log=True)\n",
    "        ax.hist(calibrated_dists['darks_wp'][i], bins=bins, color='blue', label=f\"With planet (calibrated)\", alpha=0.5, log=True)\n",
    "        ax.hist(ideal_dists['darks_so'][i], bins=bins, histtype='step', color='red', label=f\"Star only (ideal)\", linewidth=1, log=True)\n",
    "        ax.hist(ideal_dists['darks_wp'][i], bins=bins, histtype='step', color='blue', label=f\"With planet (ideal)\", linewidth=1, log=True)\n",
    "        if perturbed_dists is not None:\n",
    "            ax.hist(perturbed_dists['darks_so'][i], bins=bins, histtype='step', color='orange', linestyle=\"dashed\", label=f\"Star only (perturbed)\", linewidth=1, log=True)\n",
    "            ax.hist(perturbed_dists['darks_wp'][i], bins=bins, histtype='step', color='purple', linestyle=\"dashed\", label=f\"With planet (perturbed)\", linewidth=1, log=True)\n",
    "\n",
    "        ax.set_xlabel(\"Intensity (photons)\")\n",
    "        ax.set_ylabel(\"Number of occurences\")\n",
    "        ax.set_title(f\"Dark {i+1}\")\n",
    "        ax.legend()\n",
    "\n",
    "    # Kernel ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(15, 15))\n",
    "    for i in range(3):\n",
    "        ax = axs[i]\n",
    "\n",
    "        ax.hist(calibrated_dists['kernels_so'][i], bins=bins, color='red', label=f\"Star only (ideal)\", density=True, alpha=0.5, log=True)\n",
    "        ax.hist(calibrated_dists['kernels_wp'][i], bins=bins, color='blue', label=f\"With planet (ideal)\", density=True, alpha=0.5, log=True)\n",
    "        ax.hist(ideal_dists['kernels_so'][i], bins=bins, histtype='step', color='red', label=f\"Star only (real)\", linewidth=1, density=True, log=True)\n",
    "        ax.hist(ideal_dists['kernels_wp'][i], bins=bins, histtype='step', color='blue', label=f\"With planet (real)\", linewidth=1, density=True, log=True)\n",
    "        if perturbed_dists is not None:\n",
    "            ax.hist(perturbed_dists['kernels_so'][i], bins=bins, histtype='step', color='black', linestyle=\"dashed\", label=f\"Star only (perturbed)\", linewidth=1, density=True, log=True)\n",
    "            ax.hist(perturbed_dists['kernels_wp'][i], bins=bins, histtype='step', color='purple', linestyle=\"dashed\", label=f\"With planet (perturbed)\", linewidth=1, density=True, log=True)\n",
    "\n",
    "        ax.set_xlabel(\"Intensity (photons)\")\n",
    "        ax.set_ylabel(\"Number of occurences\")\n",
    "        ax.set_title(f\"Theoretical Kernel {i+1} (perfect cameras)\")\n",
    "        ax.legend()       \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_distributions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¢ Noise sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensitivity_to_noise(shifts=CALIBRATED_SHIFTS, shifts_total_opd=SHIFTS_TOTAL_OPD):\n",
    "\n",
    "    input_ce_rms_range, step = np.linspace(0, L.value/3, 25, retstep=True)\n",
    "    input_ce_rms_range = (input_ce_rms_range * L.unit).to(u.nm)\n",
    "    step = (step * L.unit).to(u.nm)\n",
    "    stds = []\n",
    "\n",
    "    _, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "\n",
    "    for i, input_ce_rms in enumerate(input_ce_rms_range):\n",
    "\n",
    "        dists_perturbated = generate_one_distrib(1000, STAR_SIGNALS, np.zeros(4, dtype=np.complex128)*L.unit, np.zeros(14)*L.unit, shifts_total_opd, input_ce_rms, L)\n",
    "        dists_calibrated = generate_one_distrib(1000, STAR_SIGNALS, np.zeros(4, dtype=np.complex128)*L.unit, shifts, shifts_total_opd, input_ce_rms, L)\n",
    "        dists_ideal = generate_one_distrib(1000, STAR_SIGNALS, np.zeros(4, dtype=np.complex128)*L.unit, np.zeros(14)*L.unit, np.zeros(14)*L.unit, input_ce_rms, L)\n",
    "\n",
    "        kernel_dist_perturbated = np.concatenate([*dists_perturbated['kernels_so']])\n",
    "        kernel_dist_calibrated = np.concatenate([*dists_calibrated['kernels_so']])\n",
    "        kernel_dist_ideal = np.concatenate([*dists_ideal['kernels_so']])\n",
    "\n",
    "        stds.append(np.std(kernel_dist_perturbated))\n",
    "        stds.append(np.std(kernel_dist_calibrated))\n",
    "        stds.append(np.std(kernel_dist_ideal))\n",
    "\n",
    "        ax.scatter(np.random.normal(input_ce_rms.value - step.value/5, step.value/20, len(kernel_dist_perturbated)), kernel_dist_perturbated, color='tab:red', s=5 if i == 0 else 0.1, alpha=1 if i==0 else 1, label=\"Perturbated\" if i == 0 else None)\n",
    "        ax.scatter(np.random.normal(input_ce_rms.value, step.value/20, len(kernel_dist_calibrated)), kernel_dist_calibrated, color='tab:green', s=5 if i == 0 else 0.1, alpha=1 if i==0 else 1, label=\"Calibrated\" if i == 0 else None)\n",
    "        ax.scatter(np.random.normal(input_ce_rms.value + step.value/5, step.value/20, len(kernel_dist_ideal)), kernel_dist_ideal, color='tab:blue', s=5 if i == 0 else 0.1, alpha=1 if i==0 else 1, label=\"Ideal\" if i == 0 else None)\n",
    "        \n",
    "        ax.boxplot(kernel_dist_perturbated, vert=True, positions=[input_ce_rms.value - step.value/5],widths=step.value/5, showfliers=False, manage_ticks=False)\n",
    "        ax.boxplot(kernel_dist_calibrated, vert=True, positions=[input_ce_rms.value],widths=step.value/5, showfliers=False, manage_ticks=False)\n",
    "        ax.boxplot(kernel_dist_ideal, vert=True, positions=[input_ce_rms.value + step.value/5],widths=step.value/5, showfliers=False, manage_ticks=False)\n",
    "\n",
    "    ax.set_ylim(-max(stds), max(stds))\n",
    "    ax.set_xlabel(f\"Input OPD RMS ({input_ce_rms_range.unit})\")\n",
    "    ax.set_ylabel(\"Kernel intensity (photons)\")\n",
    "    ax.set_title(\"Sensitivity to noise\")\n",
    "    ax.legend()\n",
    "\n",
    "plot_sensitivity_to_noise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚òëÔ∏è Model fitting (WIP)\n",
    "\n",
    "Distributions are cool, but in order to make deeper analysis, we want to find a model that describe these distribution using few parameters. Unfortunately, there is no straightforward way to get such model as these distribution are very particular.\n",
    "\n",
    "The next block try most of the common distribution models and show the best ones... but unfortunately, none of them seems to match üòû"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(data):\n",
    "    f = fitter.Fitter(data,\n",
    "           distributions=fitter.get_distributions())\n",
    "    f.fit()\n",
    "    f.summary()\n",
    "\n",
    "# fit(IDEAL_DISTS['kernels_so'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Test statistics\n",
    "\n",
    "A test statistic is a way of reducing the data we have to an unique number and compare this number to a threshold value. If the number is below the treshold, then the null hypothesis is favored. If it is above, the alternative hypothesis is favored. The goal is to find the best test statistic that allow to distinguish both hypothesis in a correct way\n",
    "\n",
    "- $H0$: the null hypothesis -> there is no planet\n",
    "- $H1$: the alternative hypothesis -> there is a planet\n",
    "\n",
    "- $T0$: vector of distributions obtained with H0\n",
    "- $T1$: vector of distributions obtained with H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit()\n",
    "def get_distrib_vectors(Nmc, size):\n",
    "    T0 = np.zeros((3, Nmc,size))\n",
    "    T1 = np.zeros((3, Nmc,size))\n",
    "    for i in range(Nmc):\n",
    "        dists = generate_one_distrib_njit(size)\n",
    "        for k in range(3):\n",
    "            T0[k,i] = dists[2][k]\n",
    "            T1[k,i] = dists[3][k]\n",
    "    return T0, T1\n",
    "\n",
    "T0, T1 = get_distrib_vectors(100, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean\n",
    "\n",
    "**Principle:** We take the average of the distribution and we compare it to a treshold.\n",
    "\n",
    "$$\n",
    "\\left|\\frac{1}{N}\\sum_i x_i \\right| \\stackrel{H_1}{\\underset{H_0}{\\gtrless}} \\xi\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_mean(data):\n",
    "    return np.abs(np.mean(data, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median\n",
    "\n",
    "**Principle:** We take the median of the distribution and we compare it to a treshold.\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\left| x_{\\frac{N+1}{2}} \\right| & \\text{if }N\\text{ is odd} \\\\\n",
    "\n",
    "\\left| \\frac{x_{\\frac{N}{2}} + x_{\\frac{N+1}{2}}}{2} \\right|  & \\text{if }N\\text{ is odd}\n",
    "\\end{cases}\n",
    "\\quad\\stackrel{H_1}{\\underset{H_0}{\\gtrless}} \\xi\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_median(data):\n",
    "    return np.abs(np.median(data, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argmax\n",
    "\n",
    "**Principle:** We pack our data in bins and we consider the position of the bin with the highest number of occurences. We compare it to a treshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_argmax(data, bins=100):\n",
    "    maxs = np.zeros(data.shape[0])\n",
    "    for i, dist in enumerate(data):\n",
    "        hist = np.histogram(dist, bins=bins)\n",
    "        maxs[i] = hist[1][np.argmax(hist[0])]\n",
    "    return np.abs(maxs)\n",
    "\n",
    "def ts_argmax50(data):\n",
    "    return ts_argmax(data, 50)\n",
    "\n",
    "def ts_argmax100(data):\n",
    "    return ts_argmax(data, 100)\n",
    "\n",
    "def ts_argmax500(data):\n",
    "    return ts_argmax(data, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov\n",
    "\n",
    "**Principle:** We compare the maximum distance on the cumulative distribution functions of the two distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_kolmogorov_smirnov(data):\n",
    "\n",
    "    distances = np.zeros(data.shape[0])\n",
    "\n",
    "    for d, dist in enumerate(data):\n",
    "\n",
    "        ref_dist = CALIBRATED_DISTS['kernels_so'][0]\n",
    "\n",
    "        dist = np.sort(dist)\n",
    "        ref_dist = np.sort(ref_dist)\n",
    "\n",
    "        v = np.min(np.concatenate([dist, ref_dist]))\n",
    "\n",
    "        i_ref = 0\n",
    "        i_dist = 0\n",
    "\n",
    "        count_ref = 0\n",
    "        count_dist = 0\n",
    "\n",
    "        while i_ref < len(ref_dist) and i_dist < len(dist):\n",
    "\n",
    "            if ref_dist[i_ref] < dist[i_dist]:\n",
    "                count_ref += 1\n",
    "                i_ref += 1\n",
    "            else:\n",
    "                count_dist += 1\n",
    "                i_dist += 1\n",
    "            \n",
    "            distances[d] = max(distances[d], np.abs(count_dist - count_ref) )#/ len(reference))\n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cram√®r-von Mises\n",
    "\n",
    "**Principle:** We compare the total quadratique distance on the cumulative distribution functions of the two distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_cramer_von_mises(data):\n",
    "\n",
    "    distances = np.zeros(data.shape[0])\n",
    "\n",
    "    for d, dist in enumerate(data):\n",
    "\n",
    "        ref_dist = CALIBRATED_DISTS['kernels_so'][0]\n",
    "\n",
    "        dist = np.sort(dist)\n",
    "        ref_dist = np.sort(ref_dist)\n",
    "\n",
    "        v = np.min(np.concatenate([dist, ref_dist]))\n",
    "\n",
    "        i_ref = 0\n",
    "        i_dist = 0\n",
    "\n",
    "        count_ref = 0\n",
    "        count_dist = 0\n",
    "\n",
    "        while i_ref < len(ref_dist) and i_dist < len(dist):\n",
    "\n",
    "            if ref_dist[i_ref] < dist[i_dist]:\n",
    "                count_ref += 1\n",
    "                i_ref += 1\n",
    "            else:\n",
    "                count_dist += 1\n",
    "                i_dist += 1\n",
    "            \n",
    "            distances[d] += np.abs(count_dist - count_ref) ** 2\n",
    "\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilcoxon-Mann-Whitney (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_wilcoxon_mann_whitney(data):\n",
    "\n",
    "    res = np.empty(len(data))\n",
    "\n",
    "    ref_dist = CALIBRATED_DISTS['kernels_so'][0]\n",
    "\n",
    "    for d, dist in enumerate(data):\n",
    "\n",
    "        sorted_comb = np.unique(np.sort(np.concatenate([dist, ref_dist])))\n",
    "\n",
    "        r1 = np.sum(np.searchsorted(sorted_comb, dist) + 1)\n",
    "        r2 = np.sum(np.searchsorted(sorted_comb, ref_dist) + 1)\n",
    "\n",
    "        n1 = len(dist)\n",
    "        n2 = len(ref_dist)\n",
    "\n",
    "        u1 = n1*n2 + n1*(n1+1)/2 - r1\n",
    "        u2 = n1*n2 + n2*(n2+1)/2 - r2\n",
    "\n",
    "        res[d] = min(u1, u2)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDF diff area (Aur√©lie's idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_cdf_diff_area(data):\n",
    "    \"\"\"\n",
    "    Compute the area between the 2 CDF \n",
    "    \"\"\"\n",
    "    #data\n",
    "    num_simulations = data.shape[0]\n",
    "    distances = np.zeros(num_simulations)\n",
    "    \n",
    "    ref_dist = CALIBRATED_DISTS['kernels_so'][0]\n",
    "    ref_dist_sorted = np.sort(ref_dist)\n",
    "    m = len(ref_dist_sorted)\n",
    "    cdf_ref_dist = np.arange(1, m + 1) / m\n",
    "\n",
    "    for d in range(num_simulations):\n",
    "        dist = data[d, :]\n",
    "        dist = np.sort(dist)\n",
    "        n = len(dist)\n",
    "        cdf_dist = np.arange(1, n + 1) / n\n",
    "\n",
    "        #interpolation \n",
    "        cdf_ref_dist_interp = np.interp(dist, ref_dist_sorted, cdf_ref_dist)\n",
    "\n",
    "        #test \n",
    "        cdf_diff = cdf_dist - cdf_ref_dist_interp\n",
    "        area = np.trapz(cdf_diff, dist)\n",
    "        distances[d] = area\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_STATISTICS = {\n",
    "    'Mean': ts_mean,\n",
    "    'Median': ts_median,\n",
    "    # 'argmax50': ts_argmax50,\n",
    "    # 'argmax100': ts_argmax100,\n",
    "    # 'Argmax500': ts_argmax500,\n",
    "    'Kolmogorov-Smirnov': ts_kolmogorov_smirnov,\n",
    "    'Cramer Von Mises': ts_cramer_von_mises,\n",
    "    'Wilcoxon Mann Whitney': ts_wilcoxon_mann_whitney,\n",
    "    'CDF Diff. Area': ts_cdf_diff_area\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì ROC curves\n",
    "\n",
    "ROC curves allow to compare the power of different test statistics. It show the proportion of true detection in function of the probability of false alarm. The more the curve climb fast, the better it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc(T0, T1, test_statistic, multiple_source=False):\n",
    "\n",
    "    N = len(T0)\n",
    "\n",
    "    # Computing test statistic of all the distributions\n",
    "    if not multiple_source: \n",
    "        T0_values = test_statistic(T0)\n",
    "        T1_values = test_statistic(T1)\n",
    "    else:\n",
    "        T0_values = np.zeros(T0.shape[1])\n",
    "        T1_values = np.zeros(T0.shape[1])\n",
    "        for i in range(len(T0)):\n",
    "            T0_values += test_statistic(T0[i])\n",
    "            T1_values += test_statistic(T1[i])\n",
    "\n",
    "    # Computng the maximum treshold value\n",
    "    sup = np.max(np.concatenate([T0_values, T1_values]))\n",
    "\n",
    "    thresholds = np.linspace(0, sup, 1000)\n",
    "    \n",
    "    Pfa = np.zeros(len(thresholds))\n",
    "    Pdet = np.zeros(len(thresholds))\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        Pfa[i] = np.sum(T0_values > threshold) / N\n",
    "        Pdet[i] = np.sum(T1_values > threshold) / N\n",
    "\n",
    "    return Pfa, Pdet, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(test_statistics = TEST_STATISTICS):\n",
    "\n",
    "    _, axs = plt.subplots(1, 4, figsize=(25, 5))\n",
    "\n",
    "    for k in range(4):\n",
    "        for ts_name, ts in test_statistics.items():\n",
    "            if k < 3:\n",
    "                Pfa, Pdet, _ = roc(T0[k], T1[k], ts)\n",
    "                axs[k].set_title(f\"Kernel {k+1}\")\n",
    "            else:\n",
    "                Pfa, Pdet, _ = roc(T0, T1, ts, multiple_source=True)\n",
    "                axs[k].set_title(f\"All kernels\")\n",
    "            axs[k].plot(Pfa, Pdet, label=ts_name)\n",
    "            axs[k].set_xlabel(\"Pfa\")\n",
    "            axs[k].set_ylabel(\"Pdet\")\n",
    "            axs[k].legend()\n",
    "\n",
    "    plt.suptitle(f\"ROC curves - C={CONTRAST:.1e}, Aberration RMS={INPUT_CE_RMS:.2e}\")\n",
    "    plt.show()\n",
    "\n",
    "plot_roc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí™ P-values\n",
    "\n",
    "The P-value is an indicator of the confidence we have to reject the null hypothesis.\n",
    "\n",
    "The principle consist in comparing the test statistic obtain on the data we want to test with a large bunch of data that we know to be under the null hypothesis. We then compute the proportion of test statistic that are above the one we obtained. This proportion is the P-value.\n",
    "\n",
    "Thus, the lower the P-value, the more confident we are to reject the null hypothesis. A P-value below 0.05 is commonly considered as a good indicator to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_p_values(test_statistics = TEST_STATISTICS):\n",
    "\n",
    "    col = min(2, len(test_statistics))\n",
    "    row = int(np.ceil(len(test_statistics) / col))\n",
    "\n",
    "    _, axs = plt.subplots(row, col, figsize=(5*col, 5*row))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    t = 0\n",
    "    for ts_name, ts in test_statistics.items():\n",
    "        cumulated_values = np.zeros(T0.shape[1])\n",
    "        sup = 0\n",
    "        for k in range(4):\n",
    "            if k < 3:\n",
    "                values = ts(T0[k])\n",
    "                cumulated_values += values / 3\n",
    "                label = f\"Kernel {k+1}\"\n",
    "            elif k == 3:\n",
    "                values = cumulated_values\n",
    "                label = \"Cumulated\"\n",
    "            sup = max(sup, np.max(values))\n",
    "            thresholds = np.linspace(0, sup, 1000)\n",
    "            p_values = np.zeros(len(thresholds))\n",
    "            for i, threshold in enumerate(thresholds):\n",
    "                p_values[i] = np.sum(values > threshold) / len(values)\n",
    "            axs[t].plot(thresholds, p_values, label=label)\n",
    "        axs[t].hlines(0.05, 0, sup, color='red', linestyle='dashed')\n",
    "        axs[t].set_xlabel(\"Threshold\")\n",
    "        axs[t].set_ylabel(\"P-value\")\n",
    "        axs[t].set_title(f\"P-values for {ts_name}\")\n",
    "        axs[t].legend()\n",
    "        t+=1\n",
    "    plt.show()\n",
    "\n",
    "plot_p_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div align=center>\n",
    "\n",
    "# ü™ê **Characterization**\n",
    "\n",
    "</div>\n",
    "\n",
    "## üîÑÔ∏è Angular diversity\n",
    "\n",
    "In order to determine the planet position, we need to rotate the interferometer baseline in order to rotate the transmission map. Thus, the planet signal will be modulated. By analysis this modulation (trying to fit the parametrized modulation function to the data points), it is possible to retrieve the planet position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit()\n",
    "def kernels_modulation_njit(\n",
    "    h_range:np.ndarray[float]=H_RANGE.to(u.rad).value,\n",
    "    alpha:float=ALPHA.to(u.rad).value,\n",
    "    theta:float=THETA.to(u.rad).value,\n",
    "    # contrast:float=CONTRAST\n",
    ") -> np.ndarray[float]:\n",
    "    \"\"\"\n",
    "    Compute the modulation of the kernels with respect to the hour angle\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - h_range: The range of hour angles to consider (in radian)\n",
    "    - alpha: Parallactic angle (in radian)\n",
    "    - theta: Angular separation (in radian)\n",
    "    - contrast: The contrast value\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - The modulation of the kernels.\n",
    "    \"\"\"\n",
    "\n",
    "    kernels_mod = np.zeros((3, len(h_range)))\n",
    "    for h, dh in enumerate(h_range):\n",
    "\n",
    "        projected_telescope_position = project_baseline_njit(h=dh)\n",
    "\n",
    "        signals = get_input_fields_njit(\n",
    "            norm=PLANET_FLUX,\n",
    "            projected_telescope_positions=projected_telescope_position,\n",
    "            parallactic_angle=alpha,\n",
    "            angular_separation=theta,\n",
    "        )\n",
    "\n",
    "        _, kernels, _ = kn_njit(\n",
    "            signals,\n",
    "            shifts=np.zeros(14),\n",
    "            shifts_total_opd=np.zeros(14),\n",
    "        )\n",
    "\n",
    "        for i in range(3):\n",
    "            kernels_mod[i, h] = kernels[i] * CONTRAST * OPTICAL_EFFICIENCY\n",
    "\n",
    "    return kernels_mod\n",
    "\n",
    "def kernels_modulation(\n",
    "    h_range:u.Quantity=H_RANGE,\n",
    "    alpha:u.Quantity=ALPHA,\n",
    "    theta:u.Quantity=THETA,\n",
    "    # contrast:float=CONTRAST\n",
    "):\n",
    "    return kernels_modulation_njit(h_range.to(u.rad).value, alpha.to(u.rad).value, theta.to(u.rad).value) # , contrast)\n",
    "\n",
    "kernel_modulation = [lambda h,a,t: kernels_modulation(h,a,t)[i] for i in range(3)]\n",
    "kernel_modulation_njit = [lambda h,a,t: kernels_modulation_njit(h,a,t)[i] for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iplot_kernels_modulation():\n",
    "    alpha_slider = widgets.FloatSlider(value=ALPHA.value, min=0, max=2*np.pi, step=2*np.pi/1000, description=f'Alpha (rad)')\n",
    "    theta_slider = widgets.FloatSlider(value=THETA.value, min=0, max=FOV.value, step=FOV.value/1000, description=f'Theta ({FOV.unit})')\n",
    "    contrast_slider = widgets.FloatSlider(value=int(np.log10(CONTRAST)), min=-10, max=0, step=1, description=f'Contrast')\n",
    "    plot = widgets.Image()\n",
    "    reset = widgets.Button(description=\"Reset\")\n",
    "\n",
    "    def update_plot(*args):\n",
    "        kms = kernels_modulation(H_RANGE, alpha_slider.value*u.rad, (theta_slider.value*FOV.unit).to(u.rad)) # , 10**contrast_slider.value\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(20, 3))\n",
    "\n",
    "        for i in range(3):\n",
    "            ax = axs[i]\n",
    "            ax.plot(H_RANGE, kms[i])\n",
    "            ax.set_title(f\"Kernel {i+1}\")\n",
    "            ax.set_xlabel(\"Hour angle (rad)\")\n",
    "            ax.set_ylabel(\"Intensity\")  \n",
    "\n",
    "        buffer = BytesIO()\n",
    "        plt.savefig(buffer, format='png')\n",
    "        plot.value = buffer.getvalue()\n",
    "        plt.close()\n",
    "\n",
    "    def reset_values(*args):\n",
    "        alpha_slider.value = ALPHA.value\n",
    "        theta_slider.value = THETA.value\n",
    "        contrast_slider.value = int(np.log10(CONTRAST))\n",
    "\n",
    "    alpha_slider.observe(update_plot)\n",
    "    theta_slider.observe(update_plot)\n",
    "    contrast_slider.observe(update_plot)\n",
    "    reset.on_click(reset_values)\n",
    "\n",
    "    update_plot()\n",
    "    display(widgets.VBox([alpha_slider, theta_slider, contrast_slider, plot, reset]))\n",
    "\n",
    "iplot_kernels_modulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hour_diversity(\n",
    "        data=HOUR_DIVERSITY_DATA,\n",
    "        h_range=H_RANGE,\n",
    "    ):\n",
    "\n",
    "    fits = np.zeros((3, len(h_range)))\n",
    "\n",
    "    print(\"Param    = Ideal | First guess | Found\")\n",
    "    print(\"======================================\")\n",
    "\n",
    "    popts = []\n",
    "    for i in range(3):\n",
    "        # Fit data to kernels modulations\n",
    "        p0 = [ALPHA.value + np.random.normal(0,0.1*np.pi), (THETA + np.random.normal(0,0.2)*u.mas).to(u.rad).value] # , CONTRAST * np.random.normal(1,0.1)\n",
    "\n",
    "        popt, pcov = curve_fit(\n",
    "            kernel_modulation_njit[i],\n",
    "            h_range.value,\n",
    "            data[i],\n",
    "            p0=p0,\n",
    "            maxfev=10000\n",
    "        )\n",
    "\n",
    "        print(f\"Alpha    = {ALPHA.to(u.deg):.2f} | {(p0[0]*u.rad).to(u.deg):.2f} | {(popt[0]*u.rad).to(u.deg):.2f}\")\n",
    "        print(f\"Theta    = {THETA.to(u.mas):.2f} | {(p0[1]*u.rad).to(u.mas):.2f} | {(popt[1]*u.rad).to(u.mas):.2f}\")\n",
    "        # print(f\"Contrast = {CONTRAST:.2e} | {p0[2]:.2e} | {popt[2]:.2e}\")\n",
    "        print(\"---\")\n",
    "        popts.append(popt)\n",
    "    popt = np.mean(popts, axis=0)\n",
    "\n",
    "    _, axs = plt.subplots(3, 1, figsize=(15, 15))\n",
    "    for i in range(3):\n",
    "        fits[i] = kernels_modulation_njit(h_range.to(u.rad).value, *popt)[i]\n",
    "\n",
    "        ax = axs[i]\n",
    "\n",
    "        ax.scatter(h_range, data[i], label=\"Data\",alpha=0.5)\n",
    "        ax.plot(h_range, kernels_modulation_njit(h_range.to(u.rad).value)[i], \"--\", label=\"Expected signal\")\n",
    "        ax.plot(h_range, kernels_modulation_njit(h_range.to(u.rad).value, *popts[i])[i], label=\"Specific fit\")\n",
    "        ax.plot(h_range, fits[i], label=\"Global fit\")\n",
    "\n",
    "        ax.set_xlabel(\"Observation time (hour)\")\n",
    "        ax.set_ylabel(\"Kernel intensity\")\n",
    "        ax.set_title(f\"Kernel {i+1}\")\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Param    = Ideal | Found\")\n",
    "    print(\"========================\")\n",
    "    print(f\"Alpha    = {ALPHA.to(u.deg):.2f} | {(popt[0]*u.rad).to(u.deg):.2f}\")\n",
    "    print(f\"Theta    = {THETA.to(u.mas):.2f} | {(popt[1]*u.rad).to(u.mas):.2f}\")\n",
    "    # print(f\"Contrast = {CONTRAST:.2e} | {popt[2]:.2e}\")\n",
    "\n",
    "plot_hour_diversity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåå On-sky contribution\n",
    "\n",
    "From the obtained data, it is possible to build a 2D distribution of the perceived sky contribution zones. This distribution provides insights into the possible locations of objects, enabling accurate initial estimations to fit the data points obtained based on the parallactic angle.\n",
    "\n",
    "This method involves stacking the transmission maps rotated by the baseline rotation and weighting each map by the corresponding data obtained for that baseline rotation.\n",
    "\n",
    "The base idea was already explored as \"image reconstruction\" technic using classical nulling interferometry $^1$. However, the method here is based on Kernel-Nulls which makes it more complex but less sensitive to phase aberations and by considerig the different Kernels, we can reduce the degeneracy of the solutions.\n",
    "\n",
    "Considering:\n",
    "- $T_{n}$ represents the n-th kernel's normalized transmission map.\n",
    "- $d_{n,\\beta}$ denotes the data point obtained for kernel $n$ with baseline rotation $\\beta$.\n",
    "- $\\alpha$ is the parallactic angle.\n",
    "- $\\theta$ is the angular separation.\n",
    "\n",
    "$$\n",
    "r_n(\\theta, \\alpha) = \\sum_a T_{n,h}(\\theta,\\alpha) d_{n,h}\n",
    "$$\n",
    "\n",
    "\n",
    "As the kernel outputs are antisymetric, we can filter the negative contributions:\n",
    "$$\n",
    "r'_n = \\frac{1}{2}(r_n+|r_n|)\n",
    "$$\n",
    "\n",
    "\n",
    "Finally, we can compute the product over all the kernels to get the final contribution zones:\n",
    "$$\n",
    "C(\\theta, \\alpha) = \\prod_n r'_n(\\theta, \\alpha)\n",
    "$$\n",
    "\n",
    "**References:**\n",
    "1. Angel, J. R. P., et N. J. Woolf. \"An Imaging Nulling Interferometer to Study Extrasolar Planets\". *The Astrophysical Journal* 475, no 1 (1997): 373‚Äë79. https://doi.org/10.1086/303529."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contribution_zones(\n",
    "    data: np.ndarray[float] = HOUR_DIVERSITY_DATA,\n",
    "    fov: u.Quantity = FOV,\n",
    "    resolution: int = 100,\n",
    "):\n",
    "\n",
    "    images = np.zeros((3, resolution, resolution))\n",
    "    integrated_kernels = np.zeros((3, resolution, resolution))\n",
    "\n",
    "    _, _, theta_map, _ = get_uv_map(resolution=resolution, fov=fov)\n",
    "    _, _, kernel_maps = get_transmission_map(resolution=resolution)\n",
    "    theta_map = theta_map.value / np.max(theta_map.value)\n",
    "\n",
    "    for i, h in enumerate(H_RANGE):\n",
    "\n",
    "        for j in range(3):\n",
    "            projected_telescope_position = project_baseline(h=h)\n",
    "            tm = get_transmission_map(projected_telescope_positions=projected_telescope_position)[2][j]\n",
    "            integrated_kernels[j] += np.abs(tm) #* theta_map\n",
    "            images[j] += tm * data[j, i] #* theta_map\n",
    "\n",
    "    for i in range(3):\n",
    "        integrated_kernel_intensity = np.sum(integrated_kernels[i])\n",
    "        kernel_intensity = np.sum(np.abs(kernel_maps[i]))\n",
    "\n",
    "        normalization_factor = integrated_kernel_intensity / kernel_intensity\n",
    "\n",
    "        print(f\"Kernel {i+1} : {integrated_kernel_intensity:.2e} / {kernel_intensity:.2e} = {normalization_factor:.2e}\")\n",
    "\n",
    "        images[i] /= normalization_factor\n",
    "\n",
    "    max_im = np.max(images)\n",
    "\n",
    "    _, axs = plt.subplots(1, 4, figsize=(25, 5))\n",
    "\n",
    "    planet_x, planet_y = alpha_theta_to_fov_map_coord()\n",
    "\n",
    "    for i in range(3):\n",
    "        img = images[i]\n",
    "        img[img < 0] = 0\n",
    "        im = axs[i].imshow(img, cmap=\"hot\", vmax=max_im, extent=EXTENT)\n",
    "        axs[i].set_title(f\"Kernel {i+1}\")\n",
    "        plt.colorbar(im, ax=axs[i])\n",
    "        axs[i].scatter(planet_x, planet_y, marker=\"+\", color=\"white\")\n",
    "\n",
    "    # Take mean of probable input flux\n",
    "    img = np.mean(images, axis=0)\n",
    "\n",
    "    # Filter where a probability of flux is null on one of the kernels\n",
    "    images[images < 0] = 0\n",
    "    mask = np.prod(images, axis=0)\n",
    "    img = img * mask / np.max(mask)\n",
    "\n",
    "    # Plot reconstructed image\n",
    "    im = axs[3].imshow(img, cmap=\"hot\", extent=EXTENT)\n",
    "    axs[3].set_title(\"Contribution zones\")\n",
    "    plt.colorbar(im, ax=axs[3])\n",
    "    axs[3].scatter(planet_x, planet_y, marker=\"+\", color=\"white\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_contribution_zones()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ôí Correlation map (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_map(\n",
    "        data=HOUR_DIVERSITY_DATA,\n",
    "        h_range=H_RANGE,\n",
    "    ):\n",
    "\n",
    "    resolution = 20\n",
    "    \n",
    "    _, _, alpha_map, theta_map = get_uv_map(resolution=resolution)\n",
    "\n",
    "    correl_map = np.zeros((resolution, resolution))\n",
    "\n",
    "    for x in range(resolution):\n",
    "        for y in range(resolution):\n",
    "\n",
    "            alpha = alpha_map[x, y]\n",
    "            theta = theta_map[x, y]\n",
    "\n",
    "            km = kernels_modulation(h_range, alpha=alpha, theta=theta)[0]\n",
    "\n",
    "            correl_map[x, y] = np.sum(np.corrcoef(data[0], km))\n",
    "\n",
    "\n",
    "    _, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
    "    im = ax.imshow(correl_map)\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    ax.set_title(\"Correlation map\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "correlation_map()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
